layer - > 0===============
class_name = Dense
units = 100
activation = linear
layer - > 1===============
class_name = Activation
activation = relu
layer - > 2===============
class_name = Dense
units = 70
activation = linear
layer - > 3===============
class_name = Activation
activation = relu
layer - > 4===============
class_name = Dense
units = 30
activation = linear
layer - > 5===============
class_name = Activation
activation = relu
layer - > 6===============
class_name = Dense
units = 12
activation = linear
layer - > 7===============
class_name = Activation
activation = softmax

train epochs = 300
train batch = 128
test batch = 32
train time = 13262.397298336029
loss = 1.78021247129


accuracy = 0.403101477018