{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import feather \n",
    "from mailerWithUtf8 import mail\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classify_num = 12\n",
    "epochs = 500\n",
    "batch = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feather %s seconds 0.840395450592041\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "path = 'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/april_marketing_anylze_numeric_and_bool_group11_max_min_train.feather' \n",
    "train_df = feather.read_dataframe(path)\n",
    "print('load feather %s seconds', format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feather %s seconds 0.40964412689208984\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "path = 'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/april_marketing_anylze_numeric_and_bool_group11_max_min_test.feather' \n",
    "test_df = feather.read_dataframe(path)\n",
    "print('load feather %s seconds', format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x, test_y = test_df.iloc[:, 0:-1].values, test_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], -1)   # normalize\n",
    "test_x = test_x.reshape(test_x.shape[0], -1)   # normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_y)\n",
    "encoded_Y = encoder.transform(train_y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "train_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "encoded_Y = encoder.transform(test_y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "test_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1569788"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "773180"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model ... \n",
      "Model compield in 0.0722198486328125 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print ('Compiling Model ... ')\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=train_x[0].shape ))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(40))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.4))\n",
    "model.add(Dense(12))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rms,\n",
    "          metrics=['accuracy'])\n",
    "print('Model compield in {0} seconds'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 1412809 samples, validate on 156979 samples\n",
      "Epoch 1/500\n",
      "74s - loss: 1.7757 - acc: 0.3831 - val_loss: 1.7545 - val_acc: 0.3854\n",
      "Epoch 2/500\n",
      "76s - loss: 1.7493 - acc: 0.3942 - val_loss: 1.7829 - val_acc: 0.3842\n",
      "Epoch 3/500\n",
      "74s - loss: 1.7430 - acc: 0.3973 - val_loss: 1.7475 - val_acc: 0.3970\n",
      "Epoch 4/500\n",
      "74s - loss: 1.7410 - acc: 0.3996 - val_loss: 1.7509 - val_acc: 0.3960\n",
      "Epoch 5/500\n",
      "74s - loss: 1.7390 - acc: 0.4012 - val_loss: 1.7550 - val_acc: 0.3953\n",
      "Epoch 6/500\n",
      "75s - loss: 1.7372 - acc: 0.4021 - val_loss: 1.7449 - val_acc: 0.3939\n",
      "Epoch 7/500\n",
      "74s - loss: 1.7367 - acc: 0.4029 - val_loss: 1.7400 - val_acc: 0.4043\n",
      "Epoch 8/500\n",
      "75s - loss: 1.7364 - acc: 0.4031 - val_loss: 1.7561 - val_acc: 0.3981\n",
      "Epoch 9/500\n",
      "74s - loss: 1.7379 - acc: 0.4033 - val_loss: 1.7497 - val_acc: 0.4031\n",
      "Epoch 10/500\n",
      "73s - loss: 1.7378 - acc: 0.4039 - val_loss: 1.7425 - val_acc: 0.4039\n",
      "Epoch 11/500\n",
      "73s - loss: 1.7368 - acc: 0.4045 - val_loss: 1.7524 - val_acc: 0.4008\n",
      "Epoch 12/500\n",
      "74s - loss: 1.7374 - acc: 0.4042 - val_loss: 1.7622 - val_acc: 0.3962\n",
      "Epoch 13/500\n",
      "74s - loss: 1.7381 - acc: 0.4044 - val_loss: 1.7536 - val_acc: 0.3979\n",
      "Epoch 14/500\n",
      "75s - loss: 1.7372 - acc: 0.4049 - val_loss: 1.7498 - val_acc: 0.4021\n",
      "Epoch 15/500\n",
      "76s - loss: 1.7367 - acc: 0.4050 - val_loss: 1.7392 - val_acc: 0.4018\n",
      "Epoch 16/500\n",
      "76s - loss: 1.7357 - acc: 0.4051 - val_loss: 1.7395 - val_acc: 0.4042\n",
      "Epoch 17/500\n",
      "77s - loss: 1.7349 - acc: 0.4053 - val_loss: 1.7659 - val_acc: 0.3953\n",
      "Epoch 18/500\n",
      "80s - loss: 1.7364 - acc: 0.4053 - val_loss: 1.7392 - val_acc: 0.3994\n",
      "Epoch 19/500\n",
      "77s - loss: 1.7394 - acc: 0.4059 - val_loss: 1.7477 - val_acc: 0.3969\n",
      "Epoch 20/500\n",
      "76s - loss: 1.7470 - acc: 0.4056 - val_loss: 1.7799 - val_acc: 0.3948\n",
      "Epoch 21/500\n",
      "77s - loss: 1.7422 - acc: 0.4056 - val_loss: 1.7376 - val_acc: 0.4043\n",
      "Epoch 22/500\n",
      "76s - loss: 1.7395 - acc: 0.4065 - val_loss: 1.7487 - val_acc: 0.4049\n",
      "Epoch 23/500\n",
      "77s - loss: 1.7364 - acc: 0.4065 - val_loss: 1.7471 - val_acc: 0.4047\n",
      "Epoch 24/500\n",
      "77s - loss: 1.7361 - acc: 0.4066 - val_loss: 1.7523 - val_acc: 0.4030\n",
      "Epoch 25/500\n",
      "76s - loss: 1.7390 - acc: 0.4066 - val_loss: 1.7375 - val_acc: 0.4056\n",
      "Epoch 26/500\n",
      "77s - loss: 1.7417 - acc: 0.4065 - val_loss: 1.7568 - val_acc: 0.4036\n",
      "Epoch 27/500\n",
      "77s - loss: 1.7472 - acc: 0.4059 - val_loss: 1.7685 - val_acc: 0.3968\n",
      "Epoch 28/500\n",
      "77s - loss: 1.7463 - acc: 0.4065 - val_loss: 1.7357 - val_acc: 0.4068\n",
      "Epoch 29/500\n",
      "77s - loss: 1.7401 - acc: 0.4071 - val_loss: 1.7429 - val_acc: 0.4080\n",
      "Epoch 30/500\n",
      "76s - loss: 1.7375 - acc: 0.4068 - val_loss: 1.7381 - val_acc: 0.4080\n",
      "Epoch 31/500\n",
      "77s - loss: 1.7368 - acc: 0.4070 - val_loss: 1.7349 - val_acc: 0.4090\n",
      "Epoch 32/500\n",
      "77s - loss: 1.7376 - acc: 0.4073 - val_loss: 1.7612 - val_acc: 0.4052\n",
      "Epoch 33/500\n",
      "76s - loss: 1.7361 - acc: 0.4075 - val_loss: 1.7354 - val_acc: 0.4084\n",
      "Epoch 34/500\n",
      "78s - loss: 1.7342 - acc: 0.4074 - val_loss: 1.7532 - val_acc: 0.4031\n",
      "Epoch 35/500\n",
      "77s - loss: 1.7356 - acc: 0.4078 - val_loss: 1.7401 - val_acc: 0.4064\n",
      "Epoch 36/500\n",
      "78s - loss: 1.7368 - acc: 0.4075 - val_loss: 1.7433 - val_acc: 0.4091\n",
      "Epoch 37/500\n",
      "77s - loss: 1.7353 - acc: 0.4078 - val_loss: 1.7358 - val_acc: 0.4080\n",
      "Epoch 38/500\n",
      "76s - loss: 1.7359 - acc: 0.4082 - val_loss: 1.7355 - val_acc: 0.4057\n",
      "Epoch 39/500\n",
      "76s - loss: 1.7382 - acc: 0.4078 - val_loss: 1.7482 - val_acc: 0.4071\n",
      "Epoch 40/500\n",
      "76s - loss: 1.7396 - acc: 0.4080 - val_loss: 1.7371 - val_acc: 0.4056\n",
      "Epoch 41/500\n",
      "77s - loss: 1.7383 - acc: 0.4079 - val_loss: 1.7465 - val_acc: 0.4044\n",
      "Epoch 42/500\n",
      "76s - loss: 1.7412 - acc: 0.4084 - val_loss: 1.7362 - val_acc: 0.4092\n",
      "Epoch 43/500\n",
      "77s - loss: 1.7405 - acc: 0.4083 - val_loss: 1.7442 - val_acc: 0.4053\n",
      "Epoch 44/500\n",
      "77s - loss: 1.7446 - acc: 0.4082 - val_loss: 1.7391 - val_acc: 0.4084\n",
      "Epoch 45/500\n",
      "77s - loss: 1.7461 - acc: 0.4082 - val_loss: 1.7455 - val_acc: 0.4078\n",
      "Epoch 46/500\n",
      "78s - loss: 1.7479 - acc: 0.4075 - val_loss: 1.7427 - val_acc: 0.4063\n",
      "Epoch 47/500\n",
      "77s - loss: 1.7528 - acc: 0.4066 - val_loss: 1.7576 - val_acc: 0.4025\n",
      "Epoch 48/500\n",
      "76s - loss: 1.7564 - acc: 0.4058 - val_loss: 1.7729 - val_acc: 0.3969\n",
      "Epoch 49/500\n",
      "76s - loss: 1.7583 - acc: 0.4064 - val_loss: 1.7552 - val_acc: 0.4075\n",
      "Epoch 50/500\n",
      "77s - loss: 1.7609 - acc: 0.4072 - val_loss: 1.7748 - val_acc: 0.3976\n",
      "Epoch 51/500\n",
      "75s - loss: 1.7587 - acc: 0.4077 - val_loss: 1.7659 - val_acc: 0.4014\n",
      "Epoch 52/500\n",
      "76s - loss: 1.7562 - acc: 0.4080 - val_loss: 1.7530 - val_acc: 0.4089\n",
      "Epoch 53/500\n",
      "77s - loss: 1.7545 - acc: 0.4080 - val_loss: 1.7567 - val_acc: 0.4022\n",
      "Epoch 54/500\n",
      "77s - loss: 1.7506 - acc: 0.4084 - val_loss: 1.7499 - val_acc: 0.4070\n",
      "Epoch 55/500\n",
      "76s - loss: 1.7490 - acc: 0.4087 - val_loss: 1.7512 - val_acc: 0.4070\n",
      "Epoch 56/500\n",
      "77s - loss: 1.7535 - acc: 0.4089 - val_loss: 1.7736 - val_acc: 0.4056\n",
      "Epoch 57/500\n",
      "77s - loss: 1.7524 - acc: 0.4089 - val_loss: 1.7400 - val_acc: 0.4071\n",
      "Epoch 58/500\n",
      "77s - loss: 1.7500 - acc: 0.4086 - val_loss: 1.7393 - val_acc: 0.4103\n",
      "Epoch 59/500\n",
      "78s - loss: 1.7504 - acc: 0.4086 - val_loss: 1.7616 - val_acc: 0.4001\n",
      "Epoch 60/500\n",
      "78s - loss: 1.7555 - acc: 0.4085 - val_loss: 1.7723 - val_acc: 0.4054\n",
      "Epoch 61/500\n",
      "77s - loss: 1.7509 - acc: 0.4085 - val_loss: 1.7699 - val_acc: 0.4047\n",
      "Epoch 62/500\n",
      "76s - loss: 1.7507 - acc: 0.4089 - val_loss: 1.7600 - val_acc: 0.4083\n",
      "Epoch 63/500\n",
      "76s - loss: 1.7489 - acc: 0.4089 - val_loss: 1.7479 - val_acc: 0.4076\n",
      "Epoch 64/500\n",
      "77s - loss: 1.7531 - acc: 0.4091 - val_loss: 1.7579 - val_acc: 0.4042\n",
      "Epoch 65/500\n",
      "76s - loss: 1.7529 - acc: 0.4088 - val_loss: 1.7565 - val_acc: 0.4090\n",
      "Epoch 66/500\n",
      "78s - loss: 1.7586 - acc: 0.4090 - val_loss: 1.7504 - val_acc: 0.4109\n",
      "Epoch 67/500\n",
      "76s - loss: 1.7556 - acc: 0.4089 - val_loss: 1.7589 - val_acc: 0.4055\n",
      "Epoch 68/500\n",
      "77s - loss: 1.7563 - acc: 0.4088 - val_loss: 1.7536 - val_acc: 0.4095\n",
      "Epoch 69/500\n",
      "76s - loss: 1.7532 - acc: 0.4091 - val_loss: 1.7657 - val_acc: 0.4069\n",
      "Epoch 70/500\n",
      "77s - loss: 1.7540 - acc: 0.4089 - val_loss: 1.7509 - val_acc: 0.4094\n",
      "Epoch 71/500\n",
      "78s - loss: 1.7540 - acc: 0.4088 - val_loss: 1.7583 - val_acc: 0.4103\n",
      "Epoch 72/500\n",
      "77s - loss: 1.7535 - acc: 0.4088 - val_loss: 1.7473 - val_acc: 0.4110\n",
      "Epoch 73/500\n",
      "77s - loss: 1.7493 - acc: 0.4091 - val_loss: 1.7500 - val_acc: 0.4076\n",
      "Epoch 74/500\n",
      "78s - loss: 1.7465 - acc: 0.4090 - val_loss: 1.7666 - val_acc: 0.4057\n",
      "Epoch 75/500\n",
      "76s - loss: 1.7495 - acc: 0.4090 - val_loss: 1.7435 - val_acc: 0.4080\n",
      "Epoch 76/500\n",
      "75s - loss: 1.7474 - acc: 0.4090 - val_loss: 1.7491 - val_acc: 0.4084\n",
      "Epoch 77/500\n",
      "77s - loss: 1.7451 - acc: 0.4090 - val_loss: 1.7616 - val_acc: 0.4080\n",
      "Epoch 78/500\n",
      "77s - loss: 1.7492 - acc: 0.4091 - val_loss: 1.7445 - val_acc: 0.4101\n",
      "Epoch 79/500\n",
      "76s - loss: 1.7479 - acc: 0.4088 - val_loss: 1.7506 - val_acc: 0.4049\n",
      "Epoch 80/500\n",
      "76s - loss: 1.7489 - acc: 0.4088 - val_loss: 1.7636 - val_acc: 0.4088\n",
      "Epoch 81/500\n",
      "76s - loss: 1.7546 - acc: 0.4089 - val_loss: 1.7638 - val_acc: 0.4101\n",
      "Epoch 82/500\n",
      "77s - loss: 1.7537 - acc: 0.4092 - val_loss: 1.7560 - val_acc: 0.4101\n",
      "Epoch 83/500\n",
      "79s - loss: 1.7542 - acc: 0.4089 - val_loss: 1.7575 - val_acc: 0.4089\n",
      "Epoch 84/500\n",
      "76s - loss: 1.7506 - acc: 0.4091 - val_loss: 1.7493 - val_acc: 0.4106\n",
      "Epoch 85/500\n",
      "77s - loss: 1.7499 - acc: 0.4089 - val_loss: 1.7651 - val_acc: 0.4080\n",
      "Epoch 86/500\n",
      "77s - loss: 1.7560 - acc: 0.4091 - val_loss: 1.7628 - val_acc: 0.4093\n",
      "Epoch 87/500\n",
      "77s - loss: 1.7521 - acc: 0.4089 - val_loss: 1.7631 - val_acc: 0.4060\n",
      "Epoch 88/500\n",
      "77s - loss: 1.7532 - acc: 0.4090 - val_loss: 1.7714 - val_acc: 0.4029\n",
      "Epoch 89/500\n",
      "76s - loss: 1.7486 - acc: 0.4092 - val_loss: 1.7630 - val_acc: 0.4053\n",
      "Epoch 90/500\n",
      "77s - loss: 1.7564 - acc: 0.4089 - val_loss: 1.7554 - val_acc: 0.4098\n",
      "Epoch 91/500\n",
      "78s - loss: 1.7528 - acc: 0.4090 - val_loss: 1.7582 - val_acc: 0.4079\n",
      "Epoch 92/500\n",
      "76s - loss: 1.7593 - acc: 0.4087 - val_loss: 1.7821 - val_acc: 0.4080\n",
      "Epoch 93/500\n",
      "79s - loss: 1.7638 - acc: 0.4082 - val_loss: 1.7818 - val_acc: 0.4079\n",
      "Epoch 94/500\n",
      "76s - loss: 1.7699 - acc: 0.4074 - val_loss: 1.7691 - val_acc: 0.4071\n",
      "Epoch 95/500\n",
      "76s - loss: 1.7701 - acc: 0.4066 - val_loss: 1.8063 - val_acc: 0.4075\n",
      "Epoch 96/500\n",
      "75s - loss: 1.7778 - acc: 0.4049 - val_loss: 1.7776 - val_acc: 0.4022\n",
      "Epoch 97/500\n",
      "76s - loss: 1.7763 - acc: 0.4036 - val_loss: 1.7684 - val_acc: 0.4019\n",
      "Epoch 98/500\n",
      "77s - loss: 1.7808 - acc: 0.4032 - val_loss: 1.7867 - val_acc: 0.4038\n",
      "Epoch 99/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77s - loss: 1.7916 - acc: 0.4014 - val_loss: 1.7878 - val_acc: 0.3997\n",
      "Epoch 100/500\n",
      "77s - loss: 1.7886 - acc: 0.4027 - val_loss: 1.7972 - val_acc: 0.3979\n",
      "Epoch 101/500\n",
      "77s - loss: 1.7901 - acc: 0.4027 - val_loss: 1.7897 - val_acc: 0.4046\n",
      "Epoch 102/500\n",
      "78s - loss: 1.7948 - acc: 0.4030 - val_loss: 1.8024 - val_acc: 0.3962\n",
      "Epoch 103/500\n",
      "77s - loss: 1.8055 - acc: 0.4027 - val_loss: 1.8096 - val_acc: 0.3961\n",
      "Epoch 104/500\n",
      "77s - loss: 1.8020 - acc: 0.4029 - val_loss: 1.7991 - val_acc: 0.3989\n",
      "Epoch 105/500\n",
      "77s - loss: 1.8089 - acc: 0.4032 - val_loss: 1.8095 - val_acc: 0.4045\n",
      "Epoch 106/500\n",
      "76s - loss: 1.8048 - acc: 0.4032 - val_loss: 1.8222 - val_acc: 0.3948\n",
      "Epoch 107/500\n",
      "77s - loss: 1.8093 - acc: 0.4027 - val_loss: 1.8121 - val_acc: 0.4027\n",
      "Epoch 108/500\n",
      "78s - loss: 1.8106 - acc: 0.4032 - val_loss: 1.8191 - val_acc: 0.4052\n",
      "Epoch 109/500\n",
      "79s - loss: 1.8097 - acc: 0.4030 - val_loss: 1.8240 - val_acc: 0.3950\n",
      "Epoch 110/500\n",
      "77s - loss: 1.8094 - acc: 0.4031 - val_loss: 1.8147 - val_acc: 0.4048\n",
      "Epoch 111/500\n",
      "77s - loss: 1.8073 - acc: 0.4029 - val_loss: 1.8008 - val_acc: 0.4057\n",
      "Epoch 112/500\n",
      "77s - loss: 1.8086 - acc: 0.4030 - val_loss: 1.8377 - val_acc: 0.3975\n",
      "Epoch 113/500\n",
      "77s - loss: 1.8130 - acc: 0.4029 - val_loss: 1.8218 - val_acc: 0.4039\n",
      "Epoch 114/500\n",
      "77s - loss: 1.8148 - acc: 0.4032 - val_loss: 1.8159 - val_acc: 0.4024\n",
      "Epoch 115/500\n",
      "76s - loss: 1.8210 - acc: 0.4032 - val_loss: 1.8098 - val_acc: 0.4026\n",
      "Epoch 116/500\n",
      "76s - loss: 1.8238 - acc: 0.4033 - val_loss: 1.8160 - val_acc: 0.4041\n",
      "Epoch 117/500\n",
      "76s - loss: 1.8203 - acc: 0.4036 - val_loss: 1.8459 - val_acc: 0.3882\n",
      "Epoch 118/500\n",
      "77s - loss: 1.8106 - acc: 0.4042 - val_loss: 1.8136 - val_acc: 0.4007\n",
      "Epoch 119/500\n",
      "76s - loss: 1.8103 - acc: 0.4045 - val_loss: 1.8120 - val_acc: 0.4060\n",
      "Epoch 120/500\n",
      "76s - loss: 1.8129 - acc: 0.4045 - val_loss: 1.8247 - val_acc: 0.4043\n",
      "Epoch 121/500\n",
      "78s - loss: 1.8221 - acc: 0.4047 - val_loss: 1.8343 - val_acc: 0.3917\n",
      "Epoch 122/500\n",
      "78s - loss: 1.8212 - acc: 0.4048 - val_loss: 1.8325 - val_acc: 0.4035\n",
      "Epoch 123/500\n",
      "76s - loss: 1.8135 - acc: 0.4046 - val_loss: 1.8056 - val_acc: 0.4053\n",
      "Epoch 124/500\n",
      "77s - loss: 1.8145 - acc: 0.4039 - val_loss: 1.8214 - val_acc: 0.3935\n",
      "Epoch 125/500\n",
      "78s - loss: 1.8214 - acc: 0.4036 - val_loss: 1.8365 - val_acc: 0.4027\n",
      "Epoch 126/500\n",
      "77s - loss: 1.8226 - acc: 0.4036 - val_loss: 1.8231 - val_acc: 0.3995\n",
      "Epoch 127/500\n",
      "78s - loss: 1.8213 - acc: 0.4036 - val_loss: 1.8226 - val_acc: 0.4013\n",
      "Epoch 128/500\n",
      "76s - loss: 1.8250 - acc: 0.4031 - val_loss: 1.8230 - val_acc: 0.4048\n",
      "Epoch 129/500\n",
      "77s - loss: 1.8222 - acc: 0.4035 - val_loss: 1.8258 - val_acc: 0.3943\n",
      "Epoch 130/500\n",
      "76s - loss: 1.8164 - acc: 0.4032 - val_loss: 1.8552 - val_acc: 0.3979\n",
      "Epoch 131/500\n",
      "76s - loss: 1.8207 - acc: 0.4034 - val_loss: 1.8167 - val_acc: 0.4046\n",
      "Epoch 132/500\n",
      "76s - loss: 1.8183 - acc: 0.4034 - val_loss: 1.8070 - val_acc: 0.3959\n",
      "Epoch 133/500\n",
      "76s - loss: 1.8199 - acc: 0.4038 - val_loss: 1.8212 - val_acc: 0.4029\n",
      "Epoch 134/500\n",
      "77s - loss: 1.8219 - acc: 0.4034 - val_loss: 1.8367 - val_acc: 0.4034\n",
      "Epoch 135/500\n",
      "77s - loss: 1.8244 - acc: 0.4036 - val_loss: 1.8289 - val_acc: 0.4027\n",
      "Epoch 136/500\n",
      "76s - loss: 1.8251 - acc: 0.4036 - val_loss: 1.8655 - val_acc: 0.3983\n",
      "Epoch 137/500\n",
      "77s - loss: 1.8226 - acc: 0.4034 - val_loss: 1.8293 - val_acc: 0.3981\n",
      "Epoch 138/500\n",
      "76s - loss: 1.8178 - acc: 0.4033 - val_loss: 1.8637 - val_acc: 0.3974\n",
      "Epoch 139/500\n",
      "77s - loss: 1.8245 - acc: 0.4036 - val_loss: 1.8440 - val_acc: 0.3953\n",
      "Epoch 140/500\n",
      "76s - loss: 1.8255 - acc: 0.4034 - val_loss: 1.8285 - val_acc: 0.4008\n",
      "Epoch 141/500\n",
      "76s - loss: 1.8207 - acc: 0.4034 - val_loss: 1.8364 - val_acc: 0.3998\n",
      "Epoch 142/500\n",
      "79s - loss: 1.8242 - acc: 0.4032 - val_loss: 1.8529 - val_acc: 0.3962\n",
      "Epoch 143/500\n",
      "77s - loss: 1.8329 - acc: 0.4032 - val_loss: 1.8336 - val_acc: 0.3967\n",
      "Epoch 144/500\n",
      "77s - loss: 1.8341 - acc: 0.4030 - val_loss: 1.8665 - val_acc: 0.3959\n",
      "Epoch 145/500\n",
      "76s - loss: 1.8390 - acc: 0.4030 - val_loss: 1.8359 - val_acc: 0.4028\n",
      "Epoch 146/500\n",
      "76s - loss: 1.8340 - acc: 0.4033 - val_loss: 1.8656 - val_acc: 0.3986\n",
      "Epoch 147/500\n",
      "79s - loss: 1.8423 - acc: 0.4029 - val_loss: 1.8256 - val_acc: 0.3997\n",
      "Epoch 148/500\n",
      "77s - loss: 1.8267 - acc: 0.4029 - val_loss: 1.8315 - val_acc: 0.4023\n",
      "Epoch 149/500\n",
      "76s - loss: 1.8299 - acc: 0.4029 - val_loss: 1.8620 - val_acc: 0.3972\n",
      "Epoch 150/500\n",
      "77s - loss: 1.8305 - acc: 0.4027 - val_loss: 1.8348 - val_acc: 0.3997\n",
      "Epoch 151/500\n",
      "77s - loss: 1.8321 - acc: 0.4029 - val_loss: 1.8257 - val_acc: 0.4006\n",
      "Epoch 152/500\n",
      "77s - loss: 1.8297 - acc: 0.4025 - val_loss: 1.8559 - val_acc: 0.4000\n",
      "Epoch 153/500\n",
      "77s - loss: 1.8385 - acc: 0.4026 - val_loss: 1.8287 - val_acc: 0.4024\n",
      "Epoch 154/500\n",
      "76s - loss: 1.8427 - acc: 0.4027 - val_loss: 1.8406 - val_acc: 0.3979\n",
      "Epoch 155/500\n",
      "76s - loss: 1.8369 - acc: 0.4026 - val_loss: 1.8283 - val_acc: 0.3984\n",
      "Epoch 156/500\n",
      "77s - loss: 1.8335 - acc: 0.4026 - val_loss: 1.8391 - val_acc: 0.3997\n",
      "Epoch 157/500\n",
      "76s - loss: 1.8387 - acc: 0.4020 - val_loss: 1.8498 - val_acc: 0.3989\n",
      "Epoch 158/500\n",
      "78s - loss: 1.8352 - acc: 0.4022 - val_loss: 1.8085 - val_acc: 0.4030\n",
      "Epoch 159/500\n",
      "76s - loss: 1.8394 - acc: 0.4023 - val_loss: 1.8569 - val_acc: 0.4017\n",
      "Epoch 160/500\n",
      "77s - loss: 1.8355 - acc: 0.4024 - val_loss: 1.8458 - val_acc: 0.3950\n",
      "Epoch 161/500\n",
      "78s - loss: 1.8350 - acc: 0.4022 - val_loss: 1.9334 - val_acc: 0.3912\n",
      "Epoch 162/500\n",
      "79s - loss: 1.8383 - acc: 0.4023 - val_loss: 1.8167 - val_acc: 0.4047\n",
      "Epoch 163/500\n",
      "76s - loss: 1.8464 - acc: 0.4017 - val_loss: 1.8473 - val_acc: 0.3929\n",
      "Epoch 164/500\n",
      "77s - loss: 1.8384 - acc: 0.4025 - val_loss: 1.8550 - val_acc: 0.3794\n",
      "Epoch 165/500\n",
      "77s - loss: 1.8447 - acc: 0.4020 - val_loss: 1.8406 - val_acc: 0.3957\n",
      "Epoch 166/500\n",
      "78s - loss: 1.8456 - acc: 0.4023 - val_loss: 1.8484 - val_acc: 0.3970\n",
      "Epoch 167/500\n",
      "77s - loss: 1.8488 - acc: 0.4019 - val_loss: 1.8676 - val_acc: 0.3985\n",
      "Epoch 168/500\n",
      "77s - loss: 1.8528 - acc: 0.4020 - val_loss: 1.8668 - val_acc: 0.4032\n",
      "Epoch 169/500\n",
      "78s - loss: 1.8470 - acc: 0.4020 - val_loss: 1.8813 - val_acc: 0.3959\n",
      "Epoch 170/500\n",
      "77s - loss: 1.8519 - acc: 0.4017 - val_loss: 1.8772 - val_acc: 0.3912\n",
      "Epoch 171/500\n",
      "78s - loss: 1.8522 - acc: 0.4020 - val_loss: 1.8625 - val_acc: 0.4034\n",
      "Epoch 172/500\n",
      "78s - loss: 1.8543 - acc: 0.4019 - val_loss: 1.8669 - val_acc: 0.3989\n",
      "Epoch 173/500\n",
      "77s - loss: 1.8628 - acc: 0.4019 - val_loss: 1.8964 - val_acc: 0.3979\n",
      "Epoch 174/500\n",
      "77s - loss: 1.8586 - acc: 0.4020 - val_loss: 1.8630 - val_acc: 0.3987\n",
      "Epoch 175/500\n",
      "77s - loss: 1.8463 - acc: 0.4020 - val_loss: 1.8664 - val_acc: 0.4025\n",
      "Epoch 176/500\n",
      "77s - loss: 1.8578 - acc: 0.4018 - val_loss: 1.8236 - val_acc: 0.4033\n",
      "Epoch 177/500\n",
      "78s - loss: 1.8632 - acc: 0.4018 - val_loss: 1.8934 - val_acc: 0.3981\n",
      "Epoch 178/500\n",
      "77s - loss: 1.8643 - acc: 0.4021 - val_loss: 1.8834 - val_acc: 0.4007\n",
      "Epoch 179/500\n",
      "78s - loss: 1.8595 - acc: 0.4020 - val_loss: 1.8578 - val_acc: 0.3990\n",
      "Epoch 180/500\n",
      "76s - loss: 1.8685 - acc: 0.4018 - val_loss: 1.8783 - val_acc: 0.4032\n",
      "Epoch 181/500\n",
      "77s - loss: 1.8616 - acc: 0.4017 - val_loss: 1.8379 - val_acc: 0.3998\n",
      "Epoch 182/500\n",
      "76s - loss: 1.8610 - acc: 0.4017 - val_loss: 1.8749 - val_acc: 0.4019\n",
      "Epoch 183/500\n",
      "76s - loss: 1.8621 - acc: 0.4016 - val_loss: 1.9125 - val_acc: 0.4006\n",
      "Epoch 184/500\n",
      "76s - loss: 1.8618 - acc: 0.4011 - val_loss: 1.8830 - val_acc: 0.3992\n",
      "Epoch 185/500\n",
      "76s - loss: 1.8635 - acc: 0.4010 - val_loss: 1.8583 - val_acc: 0.4019\n",
      "Epoch 186/500\n",
      "77s - loss: 1.8666 - acc: 0.4011 - val_loss: 1.9582 - val_acc: 0.3976\n",
      "Epoch 187/500\n",
      "77s - loss: 1.8757 - acc: 0.4011 - val_loss: 1.8843 - val_acc: 0.3968\n",
      "Epoch 188/500\n",
      "77s - loss: 1.8815 - acc: 0.4012 - val_loss: 1.9346 - val_acc: 0.3942\n",
      "Epoch 189/500\n",
      "76s - loss: 1.8861 - acc: 0.4012 - val_loss: 1.9426 - val_acc: 0.3974\n",
      "Epoch 190/500\n",
      "75s - loss: 1.8815 - acc: 0.4010 - val_loss: 1.8830 - val_acc: 0.3986\n",
      "Epoch 191/500\n",
      "76s - loss: 1.8816 - acc: 0.4012 - val_loss: 1.8494 - val_acc: 0.4001\n",
      "Epoch 192/500\n",
      "76s - loss: 1.8738 - acc: 0.4011 - val_loss: 1.8563 - val_acc: 0.3988\n",
      "Epoch 193/500\n",
      "77s - loss: 1.8706 - acc: 0.4015 - val_loss: 1.8735 - val_acc: 0.3969\n",
      "Epoch 194/500\n",
      "77s - loss: 1.8742 - acc: 0.4015 - val_loss: 1.8519 - val_acc: 0.3944\n",
      "Epoch 195/500\n",
      "77s - loss: 1.8802 - acc: 0.4015 - val_loss: 1.8702 - val_acc: 0.3970\n",
      "Epoch 196/500\n",
      "76s - loss: 1.8832 - acc: 0.4014 - val_loss: 1.8523 - val_acc: 0.4002\n",
      "Epoch 197/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78s - loss: 1.8832 - acc: 0.4017 - val_loss: 1.8525 - val_acc: 0.4041\n",
      "Epoch 198/500\n",
      "77s - loss: 1.8842 - acc: 0.4014 - val_loss: 1.8629 - val_acc: 0.4017\n",
      "Epoch 199/500\n",
      "78s - loss: 1.8923 - acc: 0.4017 - val_loss: 1.9323 - val_acc: 0.3995\n",
      "Epoch 200/500\n",
      "78s - loss: 1.8935 - acc: 0.4016 - val_loss: 1.9258 - val_acc: 0.3927\n",
      "Epoch 201/500\n",
      "77s - loss: 1.8958 - acc: 0.4017 - val_loss: 1.9098 - val_acc: 0.3961\n",
      "Epoch 202/500\n",
      "77s - loss: 1.9008 - acc: 0.4019 - val_loss: 1.9245 - val_acc: 0.3945\n",
      "Epoch 203/500\n",
      "78s - loss: 1.9078 - acc: 0.4015 - val_loss: 1.8987 - val_acc: 0.3983\n",
      "Epoch 204/500\n",
      "78s - loss: 1.9080 - acc: 0.4016 - val_loss: 1.8964 - val_acc: 0.3952\n",
      "Epoch 205/500\n",
      "77s - loss: 1.9106 - acc: 0.4013 - val_loss: 1.9182 - val_acc: 0.4007\n",
      "Epoch 206/500\n",
      "75s - loss: 1.9149 - acc: 0.4013 - val_loss: 1.9410 - val_acc: 0.3949\n",
      "Epoch 207/500\n",
      "76s - loss: 1.9123 - acc: 0.4016 - val_loss: 1.8918 - val_acc: 0.4031\n",
      "Epoch 208/500\n",
      "77s - loss: 1.9196 - acc: 0.4014 - val_loss: 1.9326 - val_acc: 0.4016\n",
      "Epoch 209/500\n",
      "76s - loss: 1.9132 - acc: 0.4017 - val_loss: 1.9342 - val_acc: 0.3985\n",
      "Epoch 210/500\n",
      "78s - loss: 1.9223 - acc: 0.4017 - val_loss: 1.9059 - val_acc: 0.3985\n",
      "Epoch 211/500\n",
      "76s - loss: 1.9113 - acc: 0.4019 - val_loss: 1.9355 - val_acc: 0.4002\n",
      "Epoch 212/500\n",
      "77s - loss: 1.9218 - acc: 0.4016 - val_loss: 1.9074 - val_acc: 0.3987\n",
      "Epoch 213/500\n",
      "77s - loss: 1.9198 - acc: 0.4019 - val_loss: 1.9347 - val_acc: 0.3945\n",
      "Epoch 214/500\n",
      "77s - loss: 1.9171 - acc: 0.4018 - val_loss: 1.9244 - val_acc: 0.3985\n",
      "Epoch 215/500\n",
      "77s - loss: 1.9333 - acc: 0.4018 - val_loss: 1.9542 - val_acc: 0.3997\n",
      "Epoch 216/500\n",
      "76s - loss: 1.9177 - acc: 0.4020 - val_loss: 1.9070 - val_acc: 0.3933\n",
      "Epoch 217/500\n",
      "76s - loss: 1.9268 - acc: 0.4020 - val_loss: 1.9214 - val_acc: 0.4020\n",
      "Epoch 218/500\n",
      "76s - loss: 1.9273 - acc: 0.4017 - val_loss: 1.9253 - val_acc: 0.3934\n",
      "Epoch 219/500\n",
      "77s - loss: 1.9332 - acc: 0.4021 - val_loss: 1.9450 - val_acc: 0.4010\n",
      "Epoch 220/500\n",
      "76s - loss: 1.9386 - acc: 0.4020 - val_loss: 1.9026 - val_acc: 0.4040\n",
      "Epoch 221/500\n",
      "76s - loss: 1.9313 - acc: 0.4020 - val_loss: 1.9561 - val_acc: 0.4019\n",
      "Epoch 222/500\n",
      "76s - loss: 1.9365 - acc: 0.4019 - val_loss: 1.9546 - val_acc: 0.3914\n",
      "Epoch 223/500\n",
      "77s - loss: 1.9190 - acc: 0.4021 - val_loss: 1.9129 - val_acc: 0.3988\n",
      "Epoch 224/500\n",
      "78s - loss: 1.9270 - acc: 0.4022 - val_loss: 1.8858 - val_acc: 0.3918\n",
      "Epoch 225/500\n",
      "78s - loss: 1.9085 - acc: 0.4020 - val_loss: 1.8572 - val_acc: 0.4039\n",
      "Epoch 226/500\n",
      "77s - loss: 1.8498 - acc: 0.4024 - val_loss: 1.9153 - val_acc: 0.4035\n",
      "Epoch 227/500\n",
      "76s - loss: 1.8126 - acc: 0.4030 - val_loss: 1.7864 - val_acc: 0.3969\n",
      "Epoch 228/500\n",
      "79s - loss: 1.7895 - acc: 0.4032 - val_loss: 1.7713 - val_acc: 0.4020\n",
      "Epoch 229/500\n",
      "77s - loss: 1.7858 - acc: 0.4031 - val_loss: 1.7752 - val_acc: 0.4023\n",
      "Epoch 230/500\n",
      "78s - loss: 1.7834 - acc: 0.4036 - val_loss: 1.7690 - val_acc: 0.4022\n",
      "Epoch 231/500\n",
      "77s - loss: 1.7780 - acc: 0.4037 - val_loss: 1.7659 - val_acc: 0.4045\n",
      "Epoch 232/500\n",
      "77s - loss: 1.7648 - acc: 0.4035 - val_loss: 1.7640 - val_acc: 0.4003\n",
      "Epoch 233/500\n",
      "77s - loss: 1.7656 - acc: 0.4035 - val_loss: 1.7724 - val_acc: 0.3970\n",
      "Epoch 234/500\n",
      "76s - loss: 1.7701 - acc: 0.4040 - val_loss: 1.7691 - val_acc: 0.4063\n",
      "Epoch 235/500\n",
      "75s - loss: 1.7850 - acc: 0.4038 - val_loss: 1.7718 - val_acc: 0.4025\n",
      "Epoch 236/500\n",
      "75s - loss: 1.7907 - acc: 0.4038 - val_loss: 1.7947 - val_acc: 0.4049\n",
      "Epoch 237/500\n",
      "77s - loss: 1.7964 - acc: 0.4041 - val_loss: 1.7987 - val_acc: 0.3994\n",
      "Epoch 238/500\n",
      "76s - loss: 1.8041 - acc: 0.4040 - val_loss: 1.8151 - val_acc: 0.3970\n",
      "Epoch 239/500\n",
      "77s - loss: 1.7991 - acc: 0.4040 - val_loss: 1.8070 - val_acc: 0.4013\n",
      "Epoch 240/500\n",
      "76s - loss: 1.8038 - acc: 0.4040 - val_loss: 1.8016 - val_acc: 0.4056\n",
      "Epoch 241/500\n",
      "77s - loss: 1.8178 - acc: 0.4040 - val_loss: 1.8523 - val_acc: 0.3955\n",
      "Epoch 242/500\n",
      "76s - loss: 1.8228 - acc: 0.4041 - val_loss: 1.8683 - val_acc: 0.3871\n",
      "Epoch 243/500\n",
      "76s - loss: 1.8270 - acc: 0.4042 - val_loss: 1.8220 - val_acc: 0.4016\n",
      "Epoch 244/500\n",
      "78s - loss: 1.8084 - acc: 0.4041 - val_loss: 1.8013 - val_acc: 0.3987\n",
      "Epoch 245/500\n",
      "76s - loss: 1.8155 - acc: 0.4041 - val_loss: 1.8416 - val_acc: 0.4016\n",
      "Epoch 246/500\n",
      "78s - loss: 1.8446 - acc: 0.4040 - val_loss: 1.8661 - val_acc: 0.4019\n",
      "Epoch 247/500\n",
      "77s - loss: 1.8419 - acc: 0.4039 - val_loss: 1.8274 - val_acc: 0.3993\n",
      "Epoch 248/500\n",
      "77s - loss: 1.8417 - acc: 0.4042 - val_loss: 1.8713 - val_acc: 0.4032\n",
      "Epoch 249/500\n",
      "78s - loss: 1.8444 - acc: 0.4038 - val_loss: 1.8457 - val_acc: 0.4031\n",
      "Epoch 250/500\n",
      "78s - loss: 1.8328 - acc: 0.4040 - val_loss: 1.8392 - val_acc: 0.3978\n",
      "Epoch 251/500\n",
      "78s - loss: 1.8465 - acc: 0.4039 - val_loss: 1.8423 - val_acc: 0.4000\n",
      "Epoch 252/500\n",
      "77s - loss: 1.8622 - acc: 0.4039 - val_loss: 1.8936 - val_acc: 0.4030\n",
      "Epoch 253/500\n",
      "77s - loss: 1.8857 - acc: 0.4033 - val_loss: 1.9341 - val_acc: 0.4033\n",
      "Epoch 254/500\n",
      "78s - loss: 1.8912 - acc: 0.4035 - val_loss: 1.8933 - val_acc: 0.4005\n",
      "Epoch 255/500\n",
      "76s - loss: 1.8855 - acc: 0.4034 - val_loss: 1.8866 - val_acc: 0.4046\n",
      "Epoch 256/500\n",
      "75s - loss: 1.8793 - acc: 0.4037 - val_loss: 1.8950 - val_acc: 0.3816\n",
      "Epoch 257/500\n",
      "77s - loss: 1.8640 - acc: 0.4039 - val_loss: 1.8595 - val_acc: 0.4014\n",
      "Epoch 258/500\n",
      "77s - loss: 1.8727 - acc: 0.4037 - val_loss: 1.9227 - val_acc: 0.3939\n",
      "Epoch 259/500\n",
      "77s - loss: 1.9029 - acc: 0.4036 - val_loss: 1.9016 - val_acc: 0.3989\n",
      "Epoch 260/500\n",
      "77s - loss: 1.9005 - acc: 0.4033 - val_loss: 1.9351 - val_acc: 0.4031\n",
      "Epoch 261/500\n",
      "77s - loss: 1.9125 - acc: 0.4034 - val_loss: 1.9103 - val_acc: 0.3943\n",
      "Epoch 262/500\n",
      "77s - loss: 1.8964 - acc: 0.4038 - val_loss: 1.8982 - val_acc: 0.4058\n",
      "Epoch 263/500\n",
      "77s - loss: 1.9034 - acc: 0.4038 - val_loss: 1.8892 - val_acc: 0.4039\n",
      "Epoch 264/500\n",
      "76s - loss: 1.9038 - acc: 0.4037 - val_loss: 1.8926 - val_acc: 0.4032\n",
      "Epoch 265/500\n",
      "76s - loss: 1.8938 - acc: 0.4037 - val_loss: 1.9119 - val_acc: 0.3858\n",
      "Epoch 266/500\n",
      "76s - loss: 1.9054 - acc: 0.4034 - val_loss: 1.9301 - val_acc: 0.4024\n",
      "Epoch 267/500\n",
      "76s - loss: 1.9098 - acc: 0.4036 - val_loss: 1.8977 - val_acc: 0.4026\n",
      "Epoch 268/500\n",
      "75s - loss: 1.9112 - acc: 0.4031 - val_loss: 1.9123 - val_acc: 0.4018\n",
      "Epoch 269/500\n",
      "78s - loss: 1.9227 - acc: 0.4032 - val_loss: 1.9211 - val_acc: 0.3968\n",
      "Epoch 270/500\n",
      "76s - loss: 1.9280 - acc: 0.4033 - val_loss: 1.9289 - val_acc: 0.3942\n",
      "Epoch 271/500\n",
      "75s - loss: 1.9399 - acc: 0.4032 - val_loss: 1.9298 - val_acc: 0.4015\n",
      "Epoch 272/500\n",
      "77s - loss: 1.9142 - acc: 0.4035 - val_loss: 1.9382 - val_acc: 0.4040\n",
      "Epoch 273/500\n",
      "77s - loss: 1.9096 - acc: 0.4035 - val_loss: 1.9080 - val_acc: 0.3922\n",
      "Epoch 274/500\n",
      "76s - loss: 1.9231 - acc: 0.4034 - val_loss: 1.9591 - val_acc: 0.3986\n",
      "Epoch 275/500\n",
      "77s - loss: 1.9389 - acc: 0.4032 - val_loss: 1.9474 - val_acc: 0.3974\n",
      "Epoch 276/500\n",
      "78s - loss: 1.9440 - acc: 0.4034 - val_loss: 1.9370 - val_acc: 0.3998\n",
      "Epoch 277/500\n",
      "77s - loss: 1.9306 - acc: 0.4031 - val_loss: 1.9249 - val_acc: 0.4049\n",
      "Epoch 278/500\n",
      "76s - loss: 1.9155 - acc: 0.4033 - val_loss: 1.9138 - val_acc: 0.4007\n",
      "Epoch 279/500\n",
      "77s - loss: 1.9141 - acc: 0.4035 - val_loss: 1.9317 - val_acc: 0.3937\n",
      "Epoch 280/500\n",
      "75s - loss: 1.9272 - acc: 0.4033 - val_loss: 1.9321 - val_acc: 0.4034\n",
      "Epoch 281/500\n",
      "76s - loss: 1.9020 - acc: 0.4037 - val_loss: 1.9084 - val_acc: 0.3853\n",
      "Epoch 282/500\n",
      "78s - loss: 1.9116 - acc: 0.4036 - val_loss: 1.9168 - val_acc: 0.3918\n",
      "Epoch 283/500\n",
      "77s - loss: 1.9051 - acc: 0.4037 - val_loss: 1.9184 - val_acc: 0.3919\n",
      "Epoch 284/500\n",
      "79s - loss: 1.8991 - acc: 0.4037 - val_loss: 1.9347 - val_acc: 0.4006\n",
      "Epoch 285/500\n",
      "76s - loss: 1.9396 - acc: 0.4031 - val_loss: 1.9202 - val_acc: 0.3955\n",
      "Epoch 286/500\n",
      "77s - loss: 1.9153 - acc: 0.4034 - val_loss: 1.9137 - val_acc: 0.4005\n",
      "Epoch 287/500\n",
      "77s - loss: 1.9104 - acc: 0.4035 - val_loss: 1.9219 - val_acc: 0.3985\n",
      "Epoch 288/500\n",
      "76s - loss: 1.9187 - acc: 0.4030 - val_loss: 1.9111 - val_acc: 0.3981\n",
      "Epoch 289/500\n",
      "78s - loss: 1.9149 - acc: 0.4031 - val_loss: 1.9187 - val_acc: 0.3989\n",
      "Epoch 290/500\n",
      "77s - loss: 1.9028 - acc: 0.4036 - val_loss: 1.9287 - val_acc: 0.4015\n",
      "Epoch 291/500\n",
      "77s - loss: 1.8992 - acc: 0.4035 - val_loss: 1.8990 - val_acc: 0.4020\n",
      "Epoch 292/500\n",
      "76s - loss: 1.8991 - acc: 0.4036 - val_loss: 1.8960 - val_acc: 0.4017\n",
      "Epoch 293/500\n",
      "78s - loss: 1.8923 - acc: 0.4034 - val_loss: 1.9101 - val_acc: 0.3970\n",
      "Epoch 294/500\n",
      "77s - loss: 1.9097 - acc: 0.4032 - val_loss: 1.9357 - val_acc: 0.3983\n",
      "Epoch 295/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76s - loss: 1.9138 - acc: 0.4035 - val_loss: 1.9138 - val_acc: 0.3974\n",
      "Epoch 296/500\n",
      "78s - loss: 1.8979 - acc: 0.4035 - val_loss: 1.8860 - val_acc: 0.4035\n",
      "Epoch 297/500\n",
      "78s - loss: 1.9035 - acc: 0.4032 - val_loss: 1.9202 - val_acc: 0.3994\n",
      "Epoch 298/500\n",
      "78s - loss: 1.9179 - acc: 0.4028 - val_loss: 1.9401 - val_acc: 0.3978\n",
      "Epoch 299/500\n",
      "77s - loss: 1.9235 - acc: 0.4029 - val_loss: 1.9441 - val_acc: 0.3898\n",
      "Epoch 300/500\n",
      "77s - loss: 1.9153 - acc: 0.4031 - val_loss: 1.9237 - val_acc: 0.3944\n",
      "Epoch 301/500\n",
      "78s - loss: 1.9056 - acc: 0.4031 - val_loss: 1.8933 - val_acc: 0.4004\n",
      "Epoch 302/500\n",
      "76s - loss: 1.9092 - acc: 0.4032 - val_loss: 1.9236 - val_acc: 0.4017\n",
      "Epoch 303/500\n",
      "76s - loss: 1.9229 - acc: 0.4033 - val_loss: 1.9356 - val_acc: 0.4008\n",
      "Epoch 304/500\n",
      "76s - loss: 1.9078 - acc: 0.4034 - val_loss: 1.9304 - val_acc: 0.3948\n",
      "Epoch 305/500\n",
      "77s - loss: 1.9147 - acc: 0.4030 - val_loss: 1.9334 - val_acc: 0.4020\n",
      "Epoch 306/500\n",
      "78s - loss: 1.9196 - acc: 0.4031 - val_loss: 1.9106 - val_acc: 0.4032\n",
      "Epoch 307/500\n",
      "77s - loss: 1.9222 - acc: 0.4029 - val_loss: 1.9399 - val_acc: 0.3979\n",
      "Epoch 308/500\n",
      "76s - loss: 1.9288 - acc: 0.4032 - val_loss: 1.9017 - val_acc: 0.4031\n",
      "Epoch 309/500\n",
      "76s - loss: 1.9098 - acc: 0.4032 - val_loss: 1.9122 - val_acc: 0.4026\n",
      "Epoch 310/500\n",
      "76s - loss: 1.9160 - acc: 0.4032 - val_loss: 1.9571 - val_acc: 0.3979\n",
      "Epoch 311/500\n",
      "77s - loss: 1.9250 - acc: 0.4030 - val_loss: 1.9388 - val_acc: 0.3972\n",
      "Epoch 312/500\n",
      "77s - loss: 1.9226 - acc: 0.4034 - val_loss: 1.9075 - val_acc: 0.4023\n",
      "Epoch 313/500\n",
      "78s - loss: 1.9082 - acc: 0.4032 - val_loss: 1.9220 - val_acc: 0.3983\n",
      "Epoch 314/500\n",
      "78s - loss: 1.9033 - acc: 0.4029 - val_loss: 1.9109 - val_acc: 0.4015\n",
      "Epoch 315/500\n",
      "77s - loss: 1.9090 - acc: 0.4032 - val_loss: 1.9246 - val_acc: 0.4028\n",
      "Epoch 316/500\n",
      "76s - loss: 1.9174 - acc: 0.4032 - val_loss: 1.9311 - val_acc: 0.3967\n",
      "Epoch 317/500\n",
      "75s - loss: 1.9222 - acc: 0.4033 - val_loss: 1.9314 - val_acc: 0.3990\n",
      "Epoch 318/500\n",
      "78s - loss: 1.9231 - acc: 0.4029 - val_loss: 1.9206 - val_acc: 0.3991\n",
      "Epoch 319/500\n",
      "76s - loss: 1.9062 - acc: 0.4032 - val_loss: 1.8980 - val_acc: 0.3958\n",
      "Epoch 320/500\n",
      "76s - loss: 1.9053 - acc: 0.4034 - val_loss: 1.9057 - val_acc: 0.4049\n",
      "Epoch 321/500\n",
      "76s - loss: 1.8955 - acc: 0.4032 - val_loss: 1.9092 - val_acc: 0.4036\n",
      "Epoch 322/500\n",
      "79s - loss: 1.9212 - acc: 0.4032 - val_loss: 1.9390 - val_acc: 0.3994\n",
      "Epoch 323/500\n",
      "76s - loss: 1.9108 - acc: 0.4033 - val_loss: 1.9201 - val_acc: 0.3981\n",
      "Epoch 324/500\n",
      "77s - loss: 1.9087 - acc: 0.4030 - val_loss: 1.9070 - val_acc: 0.4000\n",
      "Epoch 325/500\n",
      "77s - loss: 1.8975 - acc: 0.4031 - val_loss: 1.8913 - val_acc: 0.4004\n",
      "Epoch 326/500\n",
      "77s - loss: 1.8874 - acc: 0.4035 - val_loss: 1.8957 - val_acc: 0.3989\n",
      "Epoch 327/500\n",
      "76s - loss: 1.8918 - acc: 0.4034 - val_loss: 1.8858 - val_acc: 0.4044\n",
      "Epoch 328/500\n",
      "76s - loss: 1.8972 - acc: 0.4035 - val_loss: 1.9031 - val_acc: 0.4043\n",
      "Epoch 329/500\n",
      "76s - loss: 1.9009 - acc: 0.4038 - val_loss: 1.8950 - val_acc: 0.4052\n",
      "Epoch 330/500\n",
      "78s - loss: 1.8943 - acc: 0.4034 - val_loss: 1.8899 - val_acc: 0.4006\n",
      "Epoch 331/500\n",
      "77s - loss: 1.8836 - acc: 0.4037 - val_loss: 1.8830 - val_acc: 0.4030\n",
      "Epoch 332/500\n",
      "77s - loss: 1.8884 - acc: 0.4035 - val_loss: 1.8865 - val_acc: 0.3989\n",
      "Epoch 333/500\n",
      "76s - loss: 1.8699 - acc: 0.4034 - val_loss: 1.8804 - val_acc: 0.4048\n",
      "Epoch 334/500\n",
      "76s - loss: 1.8757 - acc: 0.4034 - val_loss: 1.8888 - val_acc: 0.3974\n",
      "Epoch 335/500\n",
      "77s - loss: 1.8719 - acc: 0.4038 - val_loss: 1.8803 - val_acc: 0.4033\n",
      "Epoch 336/500\n",
      "77s - loss: 1.8818 - acc: 0.4036 - val_loss: 1.8848 - val_acc: 0.3992\n",
      "Epoch 337/500\n",
      "75s - loss: 1.8813 - acc: 0.4035 - val_loss: 1.8886 - val_acc: 0.4003\n",
      "Epoch 338/500\n",
      "77s - loss: 1.8977 - acc: 0.4034 - val_loss: 1.9397 - val_acc: 0.3887\n",
      "Epoch 339/500\n",
      "78s - loss: 1.9195 - acc: 0.4029 - val_loss: 1.9271 - val_acc: 0.4030\n",
      "Epoch 340/500\n",
      "78s - loss: 1.8996 - acc: 0.4032 - val_loss: 1.8913 - val_acc: 0.4023\n",
      "Epoch 341/500\n",
      "77s - loss: 1.8856 - acc: 0.4034 - val_loss: 1.8935 - val_acc: 0.4024\n",
      "Epoch 342/500\n",
      "77s - loss: 1.8961 - acc: 0.4035 - val_loss: 1.9162 - val_acc: 0.4049\n",
      "Epoch 343/500\n",
      "77s - loss: 1.9039 - acc: 0.4033 - val_loss: 1.9056 - val_acc: 0.4036\n",
      "Epoch 344/500\n",
      "76s - loss: 1.9103 - acc: 0.4032 - val_loss: 1.9244 - val_acc: 0.3927\n",
      "Epoch 345/500\n",
      "77s - loss: 1.9046 - acc: 0.4032 - val_loss: 1.9048 - val_acc: 0.4010\n",
      "Epoch 346/500\n",
      "76s - loss: 1.9170 - acc: 0.4037 - val_loss: 1.9219 - val_acc: 0.4004\n",
      "Epoch 347/500\n",
      "76s - loss: 1.8934 - acc: 0.4034 - val_loss: 1.8990 - val_acc: 0.3974\n",
      "Epoch 348/500\n",
      "76s - loss: 1.9002 - acc: 0.4034 - val_loss: 1.9200 - val_acc: 0.3982\n",
      "Epoch 349/500\n",
      "76s - loss: 1.9022 - acc: 0.4035 - val_loss: 1.9047 - val_acc: 0.3988\n",
      "Epoch 350/500\n",
      "77s - loss: 1.8792 - acc: 0.4035 - val_loss: 1.8742 - val_acc: 0.4045\n",
      "Epoch 351/500\n",
      "77s - loss: 1.8750 - acc: 0.4036 - val_loss: 1.8748 - val_acc: 0.4025\n",
      "Epoch 352/500\n",
      "77s - loss: 1.8869 - acc: 0.4033 - val_loss: 1.8959 - val_acc: 0.4048\n",
      "Epoch 353/500\n",
      "76s - loss: 1.8841 - acc: 0.4030 - val_loss: 1.8873 - val_acc: 0.4057\n",
      "Epoch 354/500\n",
      "76s - loss: 1.8872 - acc: 0.4032 - val_loss: 1.9017 - val_acc: 0.3994\n",
      "Epoch 355/500\n",
      "78s - loss: 1.8807 - acc: 0.4034 - val_loss: 1.8907 - val_acc: 0.3929\n",
      "Epoch 356/500\n",
      "75s - loss: 1.8775 - acc: 0.4033 - val_loss: 1.8970 - val_acc: 0.3927\n",
      "Epoch 357/500\n",
      "77s - loss: 1.8845 - acc: 0.4031 - val_loss: 1.8890 - val_acc: 0.4013\n",
      "Epoch 358/500\n",
      "76s - loss: 1.8875 - acc: 0.4030 - val_loss: 1.8888 - val_acc: 0.3981\n",
      "Epoch 359/500\n",
      "78s - loss: 1.8796 - acc: 0.4031 - val_loss: 1.8809 - val_acc: 0.4000\n",
      "Epoch 360/500\n",
      "78s - loss: 1.8748 - acc: 0.4033 - val_loss: 1.8739 - val_acc: 0.4024\n",
      "Epoch 361/500\n",
      "77s - loss: 1.8750 - acc: 0.4032 - val_loss: 1.9012 - val_acc: 0.3881\n",
      "Epoch 362/500\n",
      "77s - loss: 1.8788 - acc: 0.4028 - val_loss: 1.8902 - val_acc: 0.4027\n",
      "Epoch 363/500\n",
      "76s - loss: 1.8974 - acc: 0.4030 - val_loss: 1.8945 - val_acc: 0.4054\n",
      "Epoch 364/500\n",
      "77s - loss: 1.8891 - acc: 0.4028 - val_loss: 1.8961 - val_acc: 0.4023\n",
      "Epoch 365/500\n",
      "76s - loss: 1.8895 - acc: 0.4029 - val_loss: 1.8987 - val_acc: 0.3963\n",
      "Epoch 366/500\n",
      "76s - loss: 1.8888 - acc: 0.4029 - val_loss: 1.9214 - val_acc: 0.3970\n",
      "Epoch 367/500\n",
      "77s - loss: 1.9069 - acc: 0.4030 - val_loss: 1.9055 - val_acc: 0.3996\n",
      "Epoch 368/500\n",
      "77s - loss: 1.9043 - acc: 0.4029 - val_loss: 1.9142 - val_acc: 0.4019\n",
      "Epoch 369/500\n",
      "76s - loss: 1.9008 - acc: 0.4029 - val_loss: 1.8856 - val_acc: 0.4040\n",
      "Epoch 370/500\n",
      "78s - loss: 1.8971 - acc: 0.4028 - val_loss: 1.9112 - val_acc: 0.3963\n",
      "Epoch 371/500\n",
      "77s - loss: 1.9188 - acc: 0.4026 - val_loss: 1.9158 - val_acc: 0.4013\n",
      "Epoch 372/500\n",
      "77s - loss: 1.9099 - acc: 0.4027 - val_loss: 1.8997 - val_acc: 0.4044\n",
      "Epoch 373/500\n",
      "77s - loss: 1.9109 - acc: 0.4029 - val_loss: 1.9369 - val_acc: 0.3975\n",
      "Epoch 374/500\n",
      "78s - loss: 1.9160 - acc: 0.4026 - val_loss: 1.9431 - val_acc: 0.3938\n",
      "Epoch 375/500\n",
      "78s - loss: 1.9148 - acc: 0.4026 - val_loss: 1.9057 - val_acc: 0.3891\n",
      "Epoch 376/500\n",
      "76s - loss: 1.8996 - acc: 0.4027 - val_loss: 1.9003 - val_acc: 0.4023\n",
      "Epoch 377/500\n",
      "78s - loss: 1.9168 - acc: 0.4027 - val_loss: 1.9127 - val_acc: 0.3944\n",
      "Epoch 378/500\n",
      "76s - loss: 1.8890 - acc: 0.4028 - val_loss: 1.8675 - val_acc: 0.3996\n",
      "Epoch 379/500\n",
      "77s - loss: 1.8756 - acc: 0.4026 - val_loss: 1.8967 - val_acc: 0.3933\n",
      "Epoch 380/500\n",
      "77s - loss: 1.8845 - acc: 0.4027 - val_loss: 1.9035 - val_acc: 0.4008\n",
      "Epoch 381/500\n",
      "78s - loss: 1.8975 - acc: 0.4030 - val_loss: 1.8862 - val_acc: 0.3910\n",
      "Epoch 382/500\n",
      "78s - loss: 1.8903 - acc: 0.4026 - val_loss: 1.8808 - val_acc: 0.4013\n",
      "Epoch 383/500\n",
      "78s - loss: 1.8888 - acc: 0.4029 - val_loss: 1.9050 - val_acc: 0.4035\n",
      "Epoch 384/500\n",
      "78s - loss: 1.9004 - acc: 0.4028 - val_loss: 1.8985 - val_acc: 0.4013\n",
      "Epoch 385/500\n",
      "77s - loss: 1.8960 - acc: 0.4030 - val_loss: 1.8836 - val_acc: 0.4054\n",
      "Epoch 386/500\n",
      "76s - loss: 1.8945 - acc: 0.4027 - val_loss: 1.8942 - val_acc: 0.4005\n",
      "Epoch 387/500\n",
      "77s - loss: 1.8979 - acc: 0.4027 - val_loss: 1.9304 - val_acc: 0.4014\n",
      "Epoch 388/500\n",
      "77s - loss: 1.9187 - acc: 0.4024 - val_loss: 1.9230 - val_acc: 0.4039\n",
      "Epoch 389/500\n",
      "77s - loss: 1.9112 - acc: 0.4022 - val_loss: 1.9161 - val_acc: 0.3994\n",
      "Epoch 390/500\n",
      "76s - loss: 1.9110 - acc: 0.4023 - val_loss: 1.9342 - val_acc: 0.4004\n",
      "Epoch 391/500\n",
      "78s - loss: 1.9256 - acc: 0.4024 - val_loss: 1.9074 - val_acc: 0.3997\n",
      "Epoch 392/500\n",
      "77s - loss: 1.8993 - acc: 0.4027 - val_loss: 1.9097 - val_acc: 0.3999\n",
      "Epoch 393/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76s - loss: 1.9037 - acc: 0.4026 - val_loss: 1.9241 - val_acc: 0.3966\n",
      "Epoch 394/500\n",
      "77s - loss: 1.9057 - acc: 0.4023 - val_loss: 1.9058 - val_acc: 0.4042\n",
      "Epoch 395/500\n",
      "76s - loss: 1.9056 - acc: 0.4022 - val_loss: 1.9145 - val_acc: 0.4033\n",
      "Epoch 396/500\n",
      "78s - loss: 1.9187 - acc: 0.4019 - val_loss: 1.9416 - val_acc: 0.3957\n",
      "Epoch 397/500\n",
      "77s - loss: 1.9322 - acc: 0.4021 - val_loss: 1.9511 - val_acc: 0.3869\n",
      "Epoch 398/500\n",
      "76s - loss: 1.9218 - acc: 0.4021 - val_loss: 1.9556 - val_acc: 0.3911\n",
      "Epoch 399/500\n",
      "76s - loss: 1.9395 - acc: 0.4018 - val_loss: 1.9579 - val_acc: 0.4013\n",
      "Epoch 400/500\n",
      "77s - loss: 1.9259 - acc: 0.4022 - val_loss: 1.9137 - val_acc: 0.4028\n",
      "Epoch 401/500\n",
      "77s - loss: 1.9217 - acc: 0.4021 - val_loss: 1.9124 - val_acc: 0.3989\n",
      "Epoch 402/500\n",
      "77s - loss: 1.9113 - acc: 0.4021 - val_loss: 1.9092 - val_acc: 0.4000\n",
      "Epoch 403/500\n",
      "78s - loss: 1.9192 - acc: 0.4020 - val_loss: 1.9294 - val_acc: 0.4019\n",
      "Epoch 404/500\n",
      "77s - loss: 1.9353 - acc: 0.4018 - val_loss: 1.9296 - val_acc: 0.4011\n",
      "Epoch 405/500\n",
      "77s - loss: 1.9232 - acc: 0.4016 - val_loss: 1.9105 - val_acc: 0.3988\n",
      "Epoch 406/500\n",
      "78s - loss: 1.9161 - acc: 0.4016 - val_loss: 1.9226 - val_acc: 0.3882\n",
      "Epoch 407/500\n",
      "77s - loss: 1.9234 - acc: 0.4012 - val_loss: 1.9479 - val_acc: 0.3989\n",
      "Epoch 408/500\n",
      "78s - loss: 1.9304 - acc: 0.4013 - val_loss: 1.9613 - val_acc: 0.3822\n",
      "Epoch 409/500\n",
      "76s - loss: 1.9394 - acc: 0.4011 - val_loss: 1.9488 - val_acc: 0.3869\n",
      "Epoch 410/500\n",
      "77s - loss: 1.9441 - acc: 0.4011 - val_loss: 1.9427 - val_acc: 0.3844\n",
      "Epoch 411/500\n",
      "76s - loss: 1.9375 - acc: 0.4011 - val_loss: 1.9485 - val_acc: 0.3983\n",
      "Epoch 412/500\n",
      "76s - loss: 1.9299 - acc: 0.4011 - val_loss: 1.9104 - val_acc: 0.3988\n",
      "Epoch 413/500\n",
      "77s - loss: 1.9035 - acc: 0.4015 - val_loss: 1.9009 - val_acc: 0.3973\n",
      "Epoch 414/500\n",
      "77s - loss: 1.9046 - acc: 0.4016 - val_loss: 1.9003 - val_acc: 0.3958\n",
      "Epoch 415/500\n",
      "77s - loss: 1.9146 - acc: 0.4012 - val_loss: 1.9211 - val_acc: 0.3904\n",
      "Epoch 416/500\n",
      "76s - loss: 1.9354 - acc: 0.4012 - val_loss: 1.9394 - val_acc: 0.3984\n",
      "Epoch 417/500\n",
      "77s - loss: 1.9313 - acc: 0.4007 - val_loss: 1.9216 - val_acc: 0.4026\n",
      "Epoch 418/500\n",
      "77s - loss: 1.9245 - acc: 0.4014 - val_loss: 1.9250 - val_acc: 0.4037\n",
      "Epoch 419/500\n",
      "77s - loss: 1.9308 - acc: 0.4011 - val_loss: 1.9425 - val_acc: 0.3943\n",
      "Epoch 420/500\n",
      "77s - loss: 1.9369 - acc: 0.4007 - val_loss: 1.9337 - val_acc: 0.3996\n",
      "Epoch 421/500\n",
      "78s - loss: 1.9269 - acc: 0.4009 - val_loss: 1.9206 - val_acc: 0.4012\n",
      "Epoch 422/500\n",
      "78s - loss: 1.9204 - acc: 0.4014 - val_loss: 1.9259 - val_acc: 0.3967\n",
      "Epoch 423/500\n",
      "75s - loss: 1.9178 - acc: 0.4012 - val_loss: 1.9431 - val_acc: 0.3945\n",
      "Epoch 424/500\n",
      "77s - loss: 1.9261 - acc: 0.4008 - val_loss: 1.9227 - val_acc: 0.3955\n",
      "Epoch 425/500\n",
      "77s - loss: 1.9254 - acc: 0.4009 - val_loss: 1.9212 - val_acc: 0.4046\n",
      "Epoch 426/500\n",
      "77s - loss: 1.9340 - acc: 0.4011 - val_loss: 1.9536 - val_acc: 0.3998\n",
      "Epoch 427/500\n",
      "77s - loss: 1.9303 - acc: 0.4015 - val_loss: 1.9253 - val_acc: 0.3845\n",
      "Epoch 428/500\n",
      "76s - loss: 1.9136 - acc: 0.4021 - val_loss: 1.9162 - val_acc: 0.3983\n",
      "Epoch 429/500\n",
      "77s - loss: 1.9048 - acc: 0.4021 - val_loss: 1.9134 - val_acc: 0.4001\n",
      "Epoch 430/500\n",
      "76s - loss: 1.9182 - acc: 0.4021 - val_loss: 1.9249 - val_acc: 0.3996\n",
      "Epoch 431/500\n",
      "78s - loss: 1.9114 - acc: 0.4019 - val_loss: 1.9066 - val_acc: 0.3952\n",
      "Epoch 432/500\n",
      "76s - loss: 1.9082 - acc: 0.4021 - val_loss: 1.9097 - val_acc: 0.3968\n",
      "Epoch 433/500\n",
      "76s - loss: 1.9025 - acc: 0.4022 - val_loss: 1.8965 - val_acc: 0.4005\n",
      "Epoch 434/500\n",
      "77s - loss: 1.9053 - acc: 0.4025 - val_loss: 1.9060 - val_acc: 0.3940\n",
      "Epoch 435/500\n",
      "79s - loss: 1.9036 - acc: 0.4024 - val_loss: 1.9120 - val_acc: 0.3931\n",
      "Epoch 436/500\n",
      "75s - loss: 1.9011 - acc: 0.4025 - val_loss: 1.9049 - val_acc: 0.4006\n",
      "Epoch 437/500\n",
      "78s - loss: 1.8959 - acc: 0.4024 - val_loss: 1.8911 - val_acc: 0.4048\n",
      "Epoch 438/500\n",
      "76s - loss: 1.8889 - acc: 0.4025 - val_loss: 1.8723 - val_acc: 0.4033\n",
      "Epoch 439/500\n",
      "77s - loss: 1.8880 - acc: 0.4026 - val_loss: 1.8945 - val_acc: 0.3996\n",
      "Epoch 440/500\n",
      "78s - loss: 1.8884 - acc: 0.4028 - val_loss: 1.8796 - val_acc: 0.4054\n",
      "Epoch 441/500\n",
      "77s - loss: 1.8915 - acc: 0.4028 - val_loss: 1.8974 - val_acc: 0.3986\n",
      "Epoch 442/500\n",
      "76s - loss: 1.8972 - acc: 0.4025 - val_loss: 1.9007 - val_acc: 0.3989\n",
      "Epoch 443/500\n",
      "77s - loss: 1.8857 - acc: 0.4029 - val_loss: 1.8847 - val_acc: 0.3872\n",
      "Epoch 444/500\n",
      "78s - loss: 1.8850 - acc: 0.4029 - val_loss: 1.8877 - val_acc: 0.4015\n",
      "Epoch 445/500\n",
      "77s - loss: 1.8867 - acc: 0.4026 - val_loss: 1.8893 - val_acc: 0.3970\n",
      "Epoch 446/500\n",
      "78s - loss: 1.8871 - acc: 0.4025 - val_loss: 1.8775 - val_acc: 0.4030\n",
      "Epoch 447/500\n",
      "76s - loss: 1.8783 - acc: 0.4024 - val_loss: 1.8698 - val_acc: 0.4010\n",
      "Epoch 448/500\n",
      "76s - loss: 1.8770 - acc: 0.4028 - val_loss: 1.8824 - val_acc: 0.4024\n",
      "Epoch 449/500\n",
      "76s - loss: 1.8745 - acc: 0.4028 - val_loss: 1.8632 - val_acc: 0.4052\n",
      "Epoch 450/500\n",
      "77s - loss: 1.8714 - acc: 0.4027 - val_loss: 1.8922 - val_acc: 0.3856\n",
      "Epoch 451/500\n",
      "77s - loss: 1.8729 - acc: 0.4026 - val_loss: 1.8714 - val_acc: 0.4016\n",
      "Epoch 452/500\n",
      "76s - loss: 1.8717 - acc: 0.4027 - val_loss: 1.8736 - val_acc: 0.3946\n",
      "Epoch 453/500\n",
      "78s - loss: 1.8690 - acc: 0.4027 - val_loss: 1.8743 - val_acc: 0.3991\n",
      "Epoch 454/500\n",
      "77s - loss: 1.8659 - acc: 0.4027 - val_loss: 1.8731 - val_acc: 0.3944\n",
      "Epoch 455/500\n",
      "78s - loss: 1.8713 - acc: 0.4030 - val_loss: 1.8758 - val_acc: 0.3975\n",
      "Epoch 456/500\n",
      "78s - loss: 1.8739 - acc: 0.4031 - val_loss: 1.8837 - val_acc: 0.3951\n",
      "Epoch 457/500\n",
      "76s - loss: 1.8659 - acc: 0.4028 - val_loss: 1.8567 - val_acc: 0.4035\n",
      "Epoch 458/500\n",
      "76s - loss: 1.8625 - acc: 0.4028 - val_loss: 1.8617 - val_acc: 0.4023\n",
      "Epoch 459/500\n",
      "77s - loss: 1.8624 - acc: 0.4026 - val_loss: 1.8648 - val_acc: 0.3917\n",
      "Epoch 460/500\n",
      "77s - loss: 1.8590 - acc: 0.4030 - val_loss: 1.8778 - val_acc: 0.3957\n",
      "Epoch 461/500\n",
      "79s - loss: 1.8607 - acc: 0.4031 - val_loss: 1.8900 - val_acc: 0.3765\n",
      "Epoch 462/500\n",
      "76s - loss: 1.8641 - acc: 0.4031 - val_loss: 1.8643 - val_acc: 0.3974\n",
      "Epoch 463/500\n",
      "77s - loss: 1.8593 - acc: 0.4027 - val_loss: 1.8593 - val_acc: 0.3988\n",
      "Epoch 464/500\n",
      "78s - loss: 1.8571 - acc: 0.4029 - val_loss: 1.8561 - val_acc: 0.3973\n",
      "Epoch 465/500\n",
      "77s - loss: 1.8547 - acc: 0.4029 - val_loss: 1.8616 - val_acc: 0.4012\n",
      "Epoch 466/500\n",
      "76s - loss: 1.8470 - acc: 0.4032 - val_loss: 1.8706 - val_acc: 0.3931\n",
      "Epoch 467/500\n",
      "78s - loss: 1.8433 - acc: 0.4031 - val_loss: 1.8467 - val_acc: 0.3886\n",
      "Epoch 468/500\n",
      "76s - loss: 1.8398 - acc: 0.4031 - val_loss: 1.8456 - val_acc: 0.3932\n",
      "Epoch 469/500\n",
      "76s - loss: 1.8388 - acc: 0.4031 - val_loss: 1.8425 - val_acc: 0.4028\n",
      "Epoch 470/500\n",
      "76s - loss: 1.8349 - acc: 0.4034 - val_loss: 1.8468 - val_acc: 0.3934\n",
      "Epoch 471/500\n",
      "78s - loss: 1.8360 - acc: 0.4034 - val_loss: 1.8327 - val_acc: 0.4050\n",
      "Epoch 472/500\n",
      "77s - loss: 1.8328 - acc: 0.4035 - val_loss: 1.8293 - val_acc: 0.4056\n",
      "Epoch 473/500\n",
      "77s - loss: 1.8331 - acc: 0.4034 - val_loss: 1.8289 - val_acc: 0.3983\n",
      "Epoch 474/500\n",
      "77s - loss: 1.8298 - acc: 0.4037 - val_loss: 1.8355 - val_acc: 0.4027\n",
      "Epoch 475/500\n",
      "78s - loss: 1.8401 - acc: 0.4037 - val_loss: 1.8470 - val_acc: 0.4011\n",
      "Epoch 476/500\n",
      "76s - loss: 1.8356 - acc: 0.4035 - val_loss: 1.8371 - val_acc: 0.4018\n",
      "Epoch 477/500\n",
      "77s - loss: 1.8359 - acc: 0.4039 - val_loss: 1.8289 - val_acc: 0.4032\n",
      "Epoch 478/500\n",
      "77s - loss: 1.8319 - acc: 0.4036 - val_loss: 1.8222 - val_acc: 0.4057\n",
      "Epoch 479/500\n",
      "77s - loss: 1.8348 - acc: 0.4037 - val_loss: 1.8548 - val_acc: 0.4021\n",
      "Epoch 480/500\n",
      "75s - loss: 1.8443 - acc: 0.4037 - val_loss: 1.8288 - val_acc: 0.4049\n",
      "Epoch 481/500\n",
      "78s - loss: 1.8358 - acc: 0.4036 - val_loss: 1.8549 - val_acc: 0.3910\n",
      "Epoch 482/500\n",
      "75s - loss: 1.8398 - acc: 0.4036 - val_loss: 1.8395 - val_acc: 0.4072\n",
      "Epoch 483/500\n",
      "76s - loss: 1.8463 - acc: 0.4036 - val_loss: 1.8780 - val_acc: 0.4003\n",
      "Epoch 484/500\n",
      "77s - loss: 1.8958 - acc: 0.4028 - val_loss: 1.9379 - val_acc: 0.3964\n",
      "Epoch 485/500\n",
      "77s - loss: 1.9330 - acc: 0.4024 - val_loss: 1.9349 - val_acc: 0.4028\n",
      "Epoch 486/500\n",
      "76s - loss: 1.9338 - acc: 0.4026 - val_loss: 1.9317 - val_acc: 0.4047\n",
      "Epoch 487/500\n",
      "77s - loss: 1.9256 - acc: 0.4024 - val_loss: 1.9136 - val_acc: 0.3902\n",
      "Epoch 488/500\n",
      "76s - loss: 1.9131 - acc: 0.4026 - val_loss: 1.9166 - val_acc: 0.3957\n",
      "Epoch 489/500\n",
      "75s - loss: 1.9009 - acc: 0.4029 - val_loss: 1.9294 - val_acc: 0.3920\n",
      "Epoch 490/500\n",
      "78s - loss: 1.8964 - acc: 0.4031 - val_loss: 1.9081 - val_acc: 0.4034\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76s - loss: 1.8916 - acc: 0.4029 - val_loss: 1.8825 - val_acc: 0.3987\n",
      "Epoch 492/500\n",
      "76s - loss: 1.8883 - acc: 0.4031 - val_loss: 1.8926 - val_acc: 0.3962\n",
      "Epoch 493/500\n",
      "76s - loss: 1.8897 - acc: 0.4032 - val_loss: 1.8876 - val_acc: 0.4040\n",
      "Epoch 494/500\n",
      "75s - loss: 1.8806 - acc: 0.4032 - val_loss: 1.8765 - val_acc: 0.4035\n",
      "Epoch 495/500\n",
      "77s - loss: 1.8807 - acc: 0.4030 - val_loss: 1.8883 - val_acc: 0.3897\n",
      "Epoch 496/500\n",
      "76s - loss: 1.8811 - acc: 0.4031 - val_loss: 1.8768 - val_acc: 0.4028\n",
      "Epoch 497/500\n",
      "78s - loss: 1.8771 - acc: 0.4031 - val_loss: 1.8798 - val_acc: 0.4018\n",
      "Epoch 498/500\n",
      "77s - loss: 1.8800 - acc: 0.4031 - val_loss: 1.8678 - val_acc: 0.4016\n",
      "Epoch 499/500\n",
      "78s - loss: 1.8788 - acc: 0.4032 - val_loss: 1.9358 - val_acc: 0.3968\n",
      "Epoch 500/500\n",
      "77s - loss: 1.8757 - acc: 0.4033 - val_loss: 1.8738 - val_acc: 0.3981\n",
      "Training duration : 38627.92874097824\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Training model...')\n",
    "model.fit(train_x, train_y , epochs=epochs, batch_size=batch,\n",
    "          shuffle=True,validation_split=0.1, verbose=2)\n",
    "print(\"Training duration : {0}\".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Send Mail\n",
      "User Email : a - DONE \n",
      "User Email : a - DONE \n",
      "User Email : 2 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 3 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 5 - DONE \n",
      "User Email : 5 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : 6 - DONE \n",
      "User Email : @ - DONE \n",
      "User Email : g - DONE \n",
      "User Email : m - DONE \n",
      "User Email : a - DONE \n",
      "User Email : i - DONE \n",
      "User Email : l - DONE \n",
      "User Email : . - DONE \n",
      "User Email : c - DONE \n",
      "User Email : o - DONE \n",
      "User Email : m - DONE \n",
      "Finish Send Mail\n"
     ]
    }
   ],
   "source": [
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model1.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model and get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773056/773180 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "test_batch = 32\n",
    "loss, accuracy = model.evaluate(test_x, test_y, batch_size=test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 39.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# send mail to alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = []\n",
    "for index, layer in enumerate(model.get_config()):\n",
    "    model_config.append(\"layer - > %d===============\" % index)\n",
    "    model_config.append(\"class_name = \" + layer[\"class_name\"] )\n",
    "    if(str(layer[\"config\"].get(\"units\", \"None\")) != \"None\"):\n",
    "        model_config.append(\"units = \" + str(layer[\"config\"].get(\"units\", \"None\")))\n",
    "    model_config.append(\"activation = \" + layer[\"config\"][\"activation\"])\n",
    "    \n",
    "model_info = '\\n'.join(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time = 0\n",
    "model_info += \"\\n\\ntrain epochs = \" + str(epochs)\n",
    "model_info += \"\\ntrain batch = \" + str(batch)\n",
    "model_info += \"\\ntest batch = \" + str(test_batch)\n",
    "model_info += \"\\ntrain time = \" + str(train_time)\n",
    "model_info += \"\\nloss = \" + str(loss)\n",
    "model_info += \"\\n\\n\\naccuracy = \" + str(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=mail()\n",
    "test.main(\"model finished\", model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write readme to report the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('readme.md', 'w+') as f:\n",
    "     f.write(model_info)\n",
    "f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "#     probabilities = model.predict(test_x[i:i+1,:], batch_size=32, verbose=0)\n",
    "#     probabilities = model.predict(test_x[i:i+1,:])\n",
    "#     probabilities = model.predict(test_x)\n",
    "#     probabilities[probabilities>=0.5] = 1\n",
    "#     probabilities[probabilities<0.5] = 0\n",
    "#     print(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
