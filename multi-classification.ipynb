{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "import feather \n",
    "from mailerWithUtf8 import mail\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feather %s seconds 1.522301435470581\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "path = 'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0710_marketing_train.feather' \n",
    "# path = 'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0710_marketing_train_sample.feather' \n",
    "train_df = feather.read_dataframe(path)\n",
    "print('load feather %s seconds', format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load feather %s seconds 0.3715088367462158\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "path = 'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0710_marketing_test.feather'\n",
    "# path = 'C:/Users/VIPLAB/Desktop/preprocess_py/marketing_analyze/0710_marketing_test_sample.feather' \n",
    "\n",
    "test_df = feather.read_dataframe(path)\n",
    "print('load feather %s seconds', format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_df.iloc[:, 0:-1].values, train_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x, test_y = test_df.iloc[:, 0:-1].values, test_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], -1)   # normalize\n",
    "test_x = test_x.reshape(test_x.shape[0], -1)   # normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# encoder = LabelBinarizer()\n",
    "# y_train = encoder.fit_transform(y_train)\n",
    "# y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_y)\n",
    "encoded_Y = encoder.transform(train_y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "train_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "encoded_Y = encoder.transform(test_y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "test_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adult', 'Game', 'HomeLife', 'Infrequent Internet User',\n",
       "       'InstantMessage-High', 'InstantMessage-Low', 'Map', 'News',\n",
       "       'No significant preference', 'Portal', 'Social-media'], dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get y unique name\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506103"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376526"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classify_num = 11\n",
    "epochs = 300\n",
    "batch = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Model ... \n",
      "Model compield in 0.12836360931396484 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print ('Compiling Model ... ')\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=train_x[0].shape ))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(classify_num))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# rms = RMSprop()\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print('Model compield in {0} seconds'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Train on 1355492 samples, validate on 150611 samples\n",
      "Epoch 1/300\n",
      "64s - loss: 1.9472 - acc: 0.2991 - val_loss: 1.9106 - val_acc: 0.3110\n",
      "Epoch 2/300\n",
      "66s - loss: 1.9029 - acc: 0.3097 - val_loss: 1.9087 - val_acc: 0.3029\n",
      "Epoch 3/300\n",
      "67s - loss: 1.8933 - acc: 0.3123 - val_loss: 1.8879 - val_acc: 0.3155\n",
      "Epoch 4/300\n",
      "66s - loss: 1.8867 - acc: 0.3144 - val_loss: 1.8857 - val_acc: 0.3155\n",
      "Epoch 5/300\n",
      "66s - loss: 1.8824 - acc: 0.3156 - val_loss: 1.8836 - val_acc: 0.3160\n",
      "Epoch 6/300\n",
      "65s - loss: 1.8775 - acc: 0.3161 - val_loss: 1.8892 - val_acc: 0.3119\n",
      "Epoch 7/300\n",
      "64s - loss: 1.8728 - acc: 0.3175 - val_loss: 1.8701 - val_acc: 0.3172\n",
      "Epoch 8/300\n",
      "65s - loss: 1.8696 - acc: 0.3183 - val_loss: 1.8710 - val_acc: 0.3183\n",
      "Epoch 9/300\n",
      "65s - loss: 1.8690 - acc: 0.3191 - val_loss: 1.8757 - val_acc: 0.3185\n",
      "Epoch 10/300\n",
      "63s - loss: 1.8660 - acc: 0.3193 - val_loss: 1.8653 - val_acc: 0.3211\n",
      "Epoch 11/300\n",
      "66s - loss: 1.8641 - acc: 0.3198 - val_loss: 1.8641 - val_acc: 0.3220\n",
      "Epoch 12/300\n",
      "66s - loss: 1.8628 - acc: 0.3203 - val_loss: 1.8623 - val_acc: 0.3219\n",
      "Epoch 13/300\n",
      "63s - loss: 1.8617 - acc: 0.3206 - val_loss: 1.8683 - val_acc: 0.3175\n",
      "Epoch 14/300\n",
      "65s - loss: 1.8603 - acc: 0.3210 - val_loss: 1.8610 - val_acc: 0.3227\n",
      "Epoch 15/300\n",
      "64s - loss: 1.8593 - acc: 0.3214 - val_loss: 1.8625 - val_acc: 0.3225\n",
      "Epoch 16/300\n",
      "64s - loss: 1.8586 - acc: 0.3215 - val_loss: 1.8681 - val_acc: 0.3216\n",
      "Epoch 17/300\n",
      "65s - loss: 1.8579 - acc: 0.3218 - val_loss: 1.8596 - val_acc: 0.3218\n",
      "Epoch 18/300\n",
      "66s - loss: 1.8571 - acc: 0.3219 - val_loss: 1.8651 - val_acc: 0.3215\n",
      "Epoch 19/300\n",
      "65s - loss: 1.8563 - acc: 0.3223 - val_loss: 1.8692 - val_acc: 0.3219\n",
      "Epoch 20/300\n",
      "65s - loss: 1.8552 - acc: 0.3227 - val_loss: 1.8833 - val_acc: 0.3197\n",
      "Epoch 21/300\n",
      "68s - loss: 1.8548 - acc: 0.3229 - val_loss: 1.8618 - val_acc: 0.3200\n",
      "Epoch 22/300\n",
      "65s - loss: 1.8552 - acc: 0.3228 - val_loss: 1.8643 - val_acc: 0.3211\n",
      "Epoch 23/300\n",
      "65s - loss: 1.8533 - acc: 0.3229 - val_loss: 1.8623 - val_acc: 0.3243\n",
      "Epoch 24/300\n",
      "66s - loss: 1.8535 - acc: 0.3232 - val_loss: 1.8622 - val_acc: 0.3225\n",
      "Epoch 25/300\n",
      "66s - loss: 1.8522 - acc: 0.3236 - val_loss: 1.8578 - val_acc: 0.3237\n",
      "Epoch 26/300\n",
      "65s - loss: 1.8518 - acc: 0.3237 - val_loss: 1.8562 - val_acc: 0.3229\n",
      "Epoch 27/300\n",
      "65s - loss: 1.8509 - acc: 0.3238 - val_loss: 1.8651 - val_acc: 0.3187\n",
      "Epoch 28/300\n",
      "67s - loss: 1.8506 - acc: 0.3240 - val_loss: 1.8677 - val_acc: 0.3224\n",
      "Epoch 29/300\n",
      "63s - loss: 1.8507 - acc: 0.3240 - val_loss: 1.8593 - val_acc: 0.3238\n",
      "Epoch 30/300\n",
      "67s - loss: 1.8499 - acc: 0.3241 - val_loss: 1.8556 - val_acc: 0.3229\n",
      "Epoch 31/300\n",
      "66s - loss: 1.8495 - acc: 0.3248 - val_loss: 1.8709 - val_acc: 0.3212\n",
      "Epoch 32/300\n",
      "66s - loss: 1.8493 - acc: 0.3241 - val_loss: 1.8582 - val_acc: 0.3232\n",
      "Epoch 33/300\n",
      "64s - loss: 1.8488 - acc: 0.3246 - val_loss: 1.8601 - val_acc: 0.3220\n",
      "Epoch 34/300\n",
      "66s - loss: 1.8482 - acc: 0.3249 - val_loss: 1.8572 - val_acc: 0.3230\n",
      "Epoch 35/300\n",
      "67s - loss: 1.8479 - acc: 0.3250 - val_loss: 1.8629 - val_acc: 0.3207\n",
      "Epoch 36/300\n",
      "67s - loss: 1.8477 - acc: 0.3247 - val_loss: 1.8592 - val_acc: 0.3231\n",
      "Epoch 37/300\n",
      "65s - loss: 1.8475 - acc: 0.3254 - val_loss: 1.8596 - val_acc: 0.3223\n",
      "Epoch 38/300\n",
      "64s - loss: 1.8467 - acc: 0.3253 - val_loss: 1.8626 - val_acc: 0.3230\n",
      "Epoch 39/300\n",
      "65s - loss: 1.8469 - acc: 0.3257 - val_loss: 1.8591 - val_acc: 0.3247\n",
      "Epoch 40/300\n",
      "65s - loss: 1.8457 - acc: 0.3257 - val_loss: 1.8579 - val_acc: 0.3231\n",
      "Epoch 41/300\n",
      "65s - loss: 1.8458 - acc: 0.3257 - val_loss: 1.8570 - val_acc: 0.3234\n",
      "Epoch 42/300\n",
      "66s - loss: 1.8454 - acc: 0.3260 - val_loss: 1.8601 - val_acc: 0.3237\n",
      "Epoch 43/300\n",
      "64s - loss: 1.8460 - acc: 0.3254 - val_loss: 1.8581 - val_acc: 0.3249\n",
      "Epoch 44/300\n",
      "65s - loss: 1.8490 - acc: 0.3253 - val_loss: 1.8613 - val_acc: 0.3220\n",
      "Epoch 45/300\n",
      "63s - loss: 1.8445 - acc: 0.3261 - val_loss: 1.8564 - val_acc: 0.3249\n",
      "Epoch 46/300\n",
      "65s - loss: 1.8444 - acc: 0.3261 - val_loss: 1.8623 - val_acc: 0.3218\n",
      "Epoch 47/300\n",
      "64s - loss: 1.8445 - acc: 0.3264 - val_loss: 1.8564 - val_acc: 0.3240\n",
      "Epoch 48/300\n",
      "64s - loss: 1.8436 - acc: 0.3263 - val_loss: 1.8632 - val_acc: 0.3199\n",
      "Epoch 49/300\n",
      "64s - loss: 1.8436 - acc: 0.3264 - val_loss: 1.8699 - val_acc: 0.3227\n",
      "Epoch 50/300\n",
      "68s - loss: 1.8452 - acc: 0.3262 - val_loss: 1.8812 - val_acc: 0.3204\n",
      "Epoch 51/300\n",
      "67s - loss: 1.8470 - acc: 0.3265 - val_loss: 1.8659 - val_acc: 0.3212\n",
      "Epoch 52/300\n",
      "66s - loss: 1.8433 - acc: 0.3269 - val_loss: 1.8606 - val_acc: 0.3225\n",
      "Epoch 53/300\n",
      "65s - loss: 1.8431 - acc: 0.3266 - val_loss: 1.8604 - val_acc: 0.3238\n",
      "Epoch 54/300\n",
      "64s - loss: 1.8431 - acc: 0.3270 - val_loss: 1.8600 - val_acc: 0.3218\n",
      "Epoch 55/300\n",
      "65s - loss: 1.8423 - acc: 0.3271 - val_loss: 1.8764 - val_acc: 0.3215\n",
      "Epoch 56/300\n",
      "65s - loss: 1.8425 - acc: 0.3267 - val_loss: 1.8613 - val_acc: 0.3217\n",
      "Epoch 57/300\n",
      "64s - loss: 1.8426 - acc: 0.3270 - val_loss: 1.8562 - val_acc: 0.3249\n",
      "Epoch 58/300\n",
      "66s - loss: 1.8432 - acc: 0.3265 - val_loss: 1.8591 - val_acc: 0.3225\n",
      "Epoch 59/300\n",
      "66s - loss: 1.8415 - acc: 0.3272 - val_loss: 1.8613 - val_acc: 0.3233\n",
      "Epoch 60/300\n",
      "64s - loss: 1.8419 - acc: 0.3269 - val_loss: 1.8639 - val_acc: 0.3193\n",
      "Epoch 61/300\n",
      "65s - loss: 1.8423 - acc: 0.3270 - val_loss: 1.8612 - val_acc: 0.3239\n",
      "Epoch 62/300\n",
      "64s - loss: 1.8422 - acc: 0.3271 - val_loss: 1.8626 - val_acc: 0.3227\n",
      "Epoch 63/300\n",
      "66s - loss: 1.8452 - acc: 0.3268 - val_loss: 1.8587 - val_acc: 0.3219\n",
      "Epoch 64/300\n",
      "64s - loss: 1.8418 - acc: 0.3271 - val_loss: 1.8686 - val_acc: 0.3222\n",
      "Epoch 65/300\n",
      "65s - loss: 1.8414 - acc: 0.3273 - val_loss: 1.8621 - val_acc: 0.3211\n",
      "Epoch 66/300\n",
      "64s - loss: 1.8473 - acc: 0.3261 - val_loss: 1.8601 - val_acc: 0.3239\n",
      "Epoch 67/300\n",
      "65s - loss: 1.8413 - acc: 0.3274 - val_loss: 1.8617 - val_acc: 0.3238\n",
      "Epoch 68/300\n",
      "64s - loss: 1.8404 - acc: 0.3275 - val_loss: 1.8618 - val_acc: 0.3224\n",
      "Epoch 69/300\n",
      "66s - loss: 1.8411 - acc: 0.3274 - val_loss: 1.8587 - val_acc: 0.3238\n",
      "Epoch 70/300\n",
      "65s - loss: 1.8406 - acc: 0.3276 - val_loss: 1.8621 - val_acc: 0.3211\n",
      "Epoch 71/300\n",
      "65s - loss: 1.8406 - acc: 0.3273 - val_loss: 1.8623 - val_acc: 0.3201\n",
      "Epoch 72/300\n",
      "63s - loss: 1.8510 - acc: 0.3260 - val_loss: 1.8710 - val_acc: 0.3212\n",
      "Epoch 73/300\n",
      "67s - loss: 1.8498 - acc: 0.3267 - val_loss: 1.8691 - val_acc: 0.3223\n",
      "Epoch 74/300\n",
      "67s - loss: 1.8407 - acc: 0.3273 - val_loss: 1.8598 - val_acc: 0.3236\n",
      "Epoch 75/300\n",
      "66s - loss: 1.8397 - acc: 0.3276 - val_loss: 1.8651 - val_acc: 0.3231\n",
      "Epoch 76/300\n",
      "65s - loss: 1.8459 - acc: 0.3266 - val_loss: 1.8683 - val_acc: 0.3211\n",
      "Epoch 77/300\n",
      "63s - loss: 1.8408 - acc: 0.3277 - val_loss: 1.8616 - val_acc: 0.3232\n",
      "Epoch 78/300\n",
      "65s - loss: 1.8396 - acc: 0.3277 - val_loss: 1.8624 - val_acc: 0.3207\n",
      "Epoch 79/300\n",
      "66s - loss: 1.8393 - acc: 0.3282 - val_loss: 1.8667 - val_acc: 0.3213\n",
      "Epoch 80/300\n",
      "65s - loss: 1.8393 - acc: 0.3281 - val_loss: 1.8616 - val_acc: 0.3233\n",
      "Epoch 81/300\n",
      "64s - loss: 1.8388 - acc: 0.3285 - val_loss: 1.8598 - val_acc: 0.3252\n",
      "Epoch 82/300\n",
      "65s - loss: 1.8389 - acc: 0.3283 - val_loss: 1.8610 - val_acc: 0.3226\n",
      "Epoch 83/300\n",
      "65s - loss: 1.8403 - acc: 0.3278 - val_loss: 1.8626 - val_acc: 0.3233\n",
      "Epoch 84/300\n",
      "65s - loss: 1.8385 - acc: 0.3280 - val_loss: 1.8641 - val_acc: 0.3238\n",
      "Epoch 85/300\n",
      "65s - loss: 1.8390 - acc: 0.3281 - val_loss: 1.8623 - val_acc: 0.3242\n",
      "Epoch 86/300\n",
      "64s - loss: 1.8383 - acc: 0.3282 - val_loss: 1.8722 - val_acc: 0.3212\n",
      "Epoch 87/300\n",
      "65s - loss: 1.8392 - acc: 0.3282 - val_loss: 1.8668 - val_acc: 0.3205\n",
      "Epoch 88/300\n",
      "67s - loss: 1.8381 - acc: 0.3285 - val_loss: 1.8694 - val_acc: 0.3217\n",
      "Epoch 89/300\n",
      "65s - loss: 1.8382 - acc: 0.3283 - val_loss: 1.8664 - val_acc: 0.3214\n",
      "Epoch 90/300\n",
      "65s - loss: 1.8380 - acc: 0.3282 - val_loss: 1.8762 - val_acc: 0.3194\n",
      "Epoch 91/300\n",
      "64s - loss: 1.8410 - acc: 0.3277 - val_loss: 1.8650 - val_acc: 0.3242\n",
      "Epoch 92/300\n",
      "66s - loss: 1.8385 - acc: 0.3282 - val_loss: 1.8694 - val_acc: 0.3224\n",
      "Epoch 93/300\n",
      "63s - loss: 1.8448 - acc: 0.3277 - val_loss: 1.8622 - val_acc: 0.3232\n",
      "Epoch 94/300\n",
      "64s - loss: 1.8389 - acc: 0.3284 - val_loss: 1.8657 - val_acc: 0.3209\n",
      "Epoch 95/300\n",
      "66s - loss: 1.8379 - acc: 0.3287 - val_loss: 1.8748 - val_acc: 0.3209\n",
      "Epoch 96/300\n",
      "64s - loss: 1.8376 - acc: 0.3283 - val_loss: 1.8637 - val_acc: 0.3230\n",
      "Epoch 97/300\n",
      "66s - loss: 1.8374 - acc: 0.3283 - val_loss: 1.8610 - val_acc: 0.3231\n",
      "Epoch 98/300\n",
      "64s - loss: 1.8377 - acc: 0.3286 - val_loss: 1.8608 - val_acc: 0.3246\n",
      "Epoch 99/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64s - loss: 1.8375 - acc: 0.3286 - val_loss: 1.8601 - val_acc: 0.3237\n",
      "Epoch 100/300\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print('Training model...')\n",
    "model.fit(train_x, train_y , epochs=epochs, batch_size=batch,\n",
    "          shuffle=True,validation_split=0.1, verbose=2)\n",
    "print(\"Training duration : {0}\".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test model and get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = 32\n",
    "loss, accuracy = model.evaluate(test_x, test_y, batch_size=test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], accuracy*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# send mail to alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_config = []\n",
    "for index, layer in enumerate(model.get_config()):\n",
    "    model_config.append(\"layer - > %d===============\" % index)\n",
    "    model_config.append(\"class_name = \" + layer[\"class_name\"] )\n",
    "    if(str(layer[\"config\"].get(\"units\", \"None\")) != \"None\"):\n",
    "        model_config.append(\"units = \" + str(layer[\"config\"].get(\"units\", \"None\")))\n",
    "    if(str(layer[\"config\"].get(\"activation\", \"None\")) != \"None\"):\n",
    "        model_config.append(\"activation = \" + layer[\"config\"][\"activation\"])\n",
    "    if(str(layer[\"config\"].get(\"rate\", \"None\")) != \"None\"):\n",
    "        model_config.append(\"rate = \" + str(layer[\"config\"][\"rate\"]))\n",
    "model_info = '\\n'.join(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_info += \"\\n\\ntrain epochs = \" + str(epochs)\n",
    "model_info += \"\\ntrain batch = \" + str(batch)\n",
    "model_info += \"\\ntest batch = \" + str(test_batch)\n",
    "model_info += \"\\ntrain time = \" + str(train_time)\n",
    "model_info += \"\\nloss = \" + str(loss)\n",
    "model_info += \"\\n\\n\\naccuracy = \" + str(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=mail()\n",
    "test.main(\"model finished\", model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write readme to report the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_info = model_info.replace(\"\\n\", \"<br>\")\n",
    "with open('readme.md', 'w+') as f:\n",
    "     f.write(md_info)\n",
    "f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(np.argmax(test_y, axis = 1), np.argmax(pred, axis = 1))\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(6, 6), dpi = 120)\n",
    "plot_confusion_matrix(cnf_matrix, classes=encoder.classes_, normalize=True, title='confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     probabilities = model.predict(test_x[i:i+1,:], batch_size=32, verbose=0)\n",
    "#     probabilities = model.predict(test_x[i:i+1,:])\n",
    "#     probabilities = model.predict(test_x)\n",
    "#     probabilities[probabilities>=0.5] = 1\n",
    "#     probabilities[probabilities<0.5] = 0\n",
    "#     print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
