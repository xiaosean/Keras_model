layer - > 0===============<br>class_name = Dense<br>units = 128<br>activation = linear<br>layer - > 1===============<br>class_name = Activation<br>activation = relu<br>layer - > 2===============<br>class_name = Dense<br>units = 64<br>activation = linear<br>layer - > 3===============<br>class_name = Activation<br>activation = relu<br>layer - > 4===============<br>class_name = Dense<br>units = 32<br>activation = linear<br>layer - > 5===============<br>class_name = Activation<br>activation = relu<br>layer - > 6===============<br>class_name = Dense<br>units = 11<br>activation = linear<br>layer - > 7===============<br>class_name = Activation<br>activation = softmax<br><br>train epochs = 300<br>train batch = 64<br>test batch = 32<br>train time = 27551.39390516281<br>loss = 2.39791243811<br><br><br>accuracy = 0.302937911327